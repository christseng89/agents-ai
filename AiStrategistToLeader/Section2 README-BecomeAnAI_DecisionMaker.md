# Section 2 : Become an AI Decision Maker

## 課程簡介

很高興歡迎各位進入《AI 高階簡報》的第二單元。

無論你是經理人、領導者、高階主管、創業家，或是正準備創業的人，這個單元都極其重要。因為我們將探討如何將 AI 應用於實際的商業專案，以及在執行過程中，作為企業領導者，該如何與技術團隊協作，做出關鍵決策。

我已準備好深入細節，幫助各位掌握推動 AI 專案所需的知識。那麼，讓我們開始吧！

在第一單元中，我們介紹了企業導入 AI 的三種方式：

1. 鼓勵團隊使用現有的 AI 產品
2. 為內部員工打造專屬的 AI 解決方案
3. 創建專屬 AI 解決方案，提供給客戶使用

接下來，我們將更詳細討論這三種方式。

---

### 第一種：內部採用 AI 工具

首先，談談第一種：**內部採用現有 AI 工具**。

必須說，這可能是本簡報唯一一次著重於「使用現有工具」，因為我們接下來的重點將放在「如何建構 AI 專案」。

#### 成為示範者，向團隊展示如何有效利用生成式 AI

對企業領導者而言，重點在於你可以成為**示範者**，向團隊展示如何有效利用生成式 AI。

簡單來說，你可以在日常工作中使用 **ChatGPT**、Anthropic 的 **Claude**、Google 的 **Gemini**，協助撰寫文件、擬定合約草稿等。

更重要的是，要坦率**分享你使用 AI 的經驗**。許多人對使用生成式 AI 仍感到「不好意思」或不敢公開。舉例來說，有一次我正在撰寫 RFP（徵求建議書），我先輸入大致架構，按下按鈕後，AI 立刻產出初稿，效果非常好。但當時我心裡想：「或許我不該告訴別人，這是 AI 幫我寫的。」然而，事實正好相反。身為領導者，我們更應該把這視為示範機會，讓大家看見這些工具如何協助我們更快完成工作。

這並不代表 AI 產出的內容可以直接採用，仍需要你親自檢視與修正。但它確實讓你有更快的起點，能在同樣時間內完成更多事情。對此，你應該感到自豪，並積極向團隊分享，鼓勵他們也善用 AI 工具。

---

#### 提示撰寫技巧

如何「提示」（prompting）也是一門學問。許多人都在學習如何寫出最能引導 AI 給出好答案的提示文字。ServiceNow 曾提出一個著名的提示撰寫框架 **RISEN**，可作為專業提示的參考：

* **R – Role（角色）**：告訴 AI 它扮演什麼角色，例如專業合約撰寫人、財務顧問、會計師等。
* **I – Information（資訊）**：提供背景資訊與情境，讓 AI 更能理解你的需求。
* **S – Steps（步驟）**：清楚指示你希望 AI 執行的步驟，例如 **步驟 1、2、3**……。
* **E – End Goal（目標）**：明確告訴 AI，你期望的最終成果是什麼。
* **N – Narrowing（範圍限定）**：設定具體的限制，例如「請控制在兩段內」、「請提供優缺點分析」等。

---

##### RISEN Prompt Framework Example

✅ **R — Role**

> You are an expert accountant.

✅ **I — Information**

> This is the information about the company:
> （此處填入公司相關資訊）

✅ **S — Steps**

> This is what I want you to do:
>
> 1. (…)
> 2. (…)
> 3. (…)

✅ **E — End Goal**

> What I’m looking for is (…)

✅ **N — Narrowing**

> Please do this in less than 2 paragraphs.

這個框架並不是硬性規定，但對想要提升**提示技巧**的人來說，是相當實用的參考。

此外，你自己應該成為 AI 工具的早期使用者與推動者。

若你的公司是 Office 365 的用戶，就應該試試 **Microsoft Copilot**；或者利用 AI 會議記錄工具，自動生成會議紀要與待辦事項。成為第一個使用這些工具的人，並向團隊展示它們帶來的效率提升，因為這種正向影響會快速擴散。

---

#### 鼓勵團隊使用 AI 工具

同時，你也應該鼓勵團隊在日常工作中，利用 AI 工具提升效率，並支持他們嘗試各種創新工具。例如：

* 若你管理的是技術團隊，可嘗試使用 **Cursor** 或 GitHub Copilot 提升程式開發效率。
* 若你管理的是創意團隊，**Adobe Firefly** 或類似工具是好選擇。
* 若你管理的是銷售團隊，則可考慮 Salesforce Einstein GPT 或其他能總結客戶對話、產生銷售郵件的生成式工具。

當團隊中有人率先嘗試 AI 工具並帶來具體成效時，務必公開肯定他們的貢獻。讓大家看見，這種創新行為會受到鼓勵與讚賞，進而促進更廣泛的 AI 採用。

---

### 第二種與第三種：部署 AI、打造 AI 解決方案

談完「使用 AI」，接下來，我們要進入更深入的部分：**部署 AI、打造 AI 解決方案**，也就是第二種與第三種應用情境。接下來的簡報，都將圍繞這個主題展開。

以下先提供一些真實案例，說明如何在**企業內部**導入 AI：

* **摩根士丹利（Morgan Stanley）**
  推出了一個搭載 GPT-4 的會議紀要工具，協助財務顧問快速產生會議摘要及待辦事項。該專案的使用率達 98%，每週為顧問節省 10-15 小時，是非常成功的案例。在第三單元討論變革管理時，我們還會再次提到它。

* **Uber**
  開發了一款 IT 協作 Copilot，與 Slack 深度整合，能即時讀取技術文件及過往支援紀錄。每月處理 4.5 萬筆問題，為工程團隊節省了 1.3 萬小時工時，是 AI 帶來自動化與增強的典型案例。

再來看看**外部應用**的例子：

* **麻省總醫院（Massachusetts General Brigham）**
  試點了一個平台，協助醫師回覆病患的緊急詢問。有 58% 的回覆完全不需要人工修改，即可直接傳送給病患，成效令人印象深刻。

* **Duolingo** ([https://www.duolingo.com/])
  推出了一個結合 AI 技術的**語言學習系統**。許多人或許不知道，這背後其實是基於 GPT-4。它能與使用者進行對話，並解釋語法錯誤。Duolingo 表示，AI 功能讓他們的每日活躍用戶增加 51%，付費訂閱用戶增加 43%，營收成長 40%。這是 AI 驅動商業成功的典型例子。

當然，並非所有 AI 專案都如此順利。目前生成式 AI 確實正處於極大熱潮。在第三單元，我們也會探討那些不那麼成功的案例，以及背後的原因。

---

### 如何將 LLM 應用於商業問題

接下來，我們要探討如何將 LLM 應用於解決具體商業問題。

若要超越「ChatGPT Wrapper」的簡單介面，真正將 AI 技術落地，通常有兩種技術途徑：

---

#### 1. 🏋️‍♂️訓練階段（Training Time）

在模型訓練階段，利用額外資料進行優化，使模型更適應企業的特定任務。

##### 微調（Fine-Tuning）

* 使用一個已經訓練好的模型，稱為「基礎模型（Base Model）」
* 再利用一些專有資料進一步訓練
* 「遷移學習（Transfer Learning）」：大型語言模型（LLMs）通常會保留原本的基礎知識

---

##### 使用前沿模型進行微調（…WITH A FRONTIER MODEL）

* 實驗室提供 API，可用於微調
* 用來增加細微差異、語氣，或修正特殊情境
* 通常使用較小的資料集（大約 **200** 筆），並搭配 **Guardrails**（安全防護措施）

---

##### 使用開源模型進行微調（…WITH AN OPEN-SOURCE MODEL）

* 建立你自己的專屬 LLM
* 通常需要規模較大的資料集（**20,000** 筆以上）

---

多數企業不會從零開始訓練模型，因為成本非常高昂。例如，OpenAI 為訓練 GPT-4 就花費超過 1 億美元。相對而言，企業多從**預訓練好的基礎模型（Base Model）**出發，再用自有的**專業數據進行微調**。如此便能保留原本的知識，同時使模型更貼近企業的專屬情境。

唯一較特別的例子是 Bloomberg，他們從零開始訓練了專注於金融領域的 BloombergGPT。

---

#### 2. 🏃‍♂️ **推理時間（Inference Time）推論階段優化

模型已訓練完成，透過**巧妙的提示設計（prompting）**，讓模型產生更符合業務需求的結果。

##### 提示（Prompting）

* 思維鏈提示（Chain of Thought prompting）
* 多次提示（Multi-shot prompting），包含範例

---

##### RAG - 檢索增強生成（Retrieval Augmented Generation）

* 查找與使用者問題相關的資訊
* 將查到的資訊作為 **Prompt** 的上下文

---

### 智能代理（Agent）

* 工作流程（Workflows）
* 推理能力（Reasoning）
* 自主性（Autonomy）

---

除了微調，還有另一種優化方法：**推論階段優化**，如：

* **Chain of Thought Prompting**
  在提示中明確要求模型「逐步推理」，效果往往比直接問答更好。

* **Multi-shot Prompting**
  在提示中加入多個問題與回答範例，幫助模型掌握語氣、格式與情境。雖然聽起來像是訓練，其實並不會改變模型參數，而是利用提示的內容，讓模型生成更精確的結果。

另一個非常熱門的技術是 **RAG（檢索增強生成）**。其原理很簡單，就是在向模型提出問題時，同時提供一段相關背景知識，讓模型回答得更精準，而不必花費巨額訓練成本。接下來，我們會更深入討論 RAG 的原理與實作方式。

最後，就是目前最受關注的主題：**AI Agents（AI 代理人）**。這領域相當火熱。市面上對「Agent」的定義眾說紛紜，有些人稱其為「工作流（Workflow）」— 即串接多個模型執行複雜任務；有些人強調推理（Reasoning）— 模型先思考再分步執行；還有人談到自主性（Autonomy）— 讓 AI 自主決定下一步該做什麼。雖然聽起來有些神秘，但我們會在後續課程中完整解析，讓這些概念變得清晰易懂。

恭喜各位完成這一堂內容滿滿的課程！這為第二單元奠定了基礎。下一堂課，我們將深入探討 RAG，了解它如何輕鬆地為模型增加專業知識。

---

## **RAG（檢索增強生成）** 和 **微調（Fine-Tuning）to Adding Domain Expertise to AI Solutions**。

如之前所說，**RAG（檢索增強生成）** 和 **微調（Fine-Tuning）**這兩者都是讓你的 AI 解決方案能融入**領域專業知識**的方法。

- RAG 是一種**推理階段（Inference Time）**的技術，也就是在模型執行的時候，動態加入相關的上下文 to **Prompt**。
- 微調，則是在**訓練階段（Training Time）**透過額外的訓練資料**Datasets**，讓模型在技能和專業度上有更細緻的掌握。

那麼我們先從更深入的 RAG 開始說起。

---

### 小概念與大概念：RAG 的雙重面向

在解釋 RAG 時，我喜歡告訴大家，RAG 背後有一個 **小概念**，以及一個 **大概念**。現在我會跟你們一起探討兩者。

接下來我要展示一個技術性示意圖，應該是整場簡報裡唯一一個技術圖表，所以請跟我一起撐過去。

這會很有幫助，能讓你們理解 RAG 的運作方式，並且能跟自己的團隊討論這個話題。

---

#### 小概念：加背景資訊就能提升表現

先談小概念： **無法比對同義詞或語意相近的文字**

想像一下，如果你在呼叫一個大型語言模型（LLM）時，在 Prompt 裡多加一些背景資訊，往往就能提升它的表現。

例如：

* 使用者提出一個問題
* 你的系統正在編寫那個「中間程式塊」
* 通常情況下，你會把問題直接送給 LLM，取得回答，再把回答回傳給使用者

- 在 RAG 的作法裡，你會先想：「我能不能先去資料庫查一查，有沒有跟這個問題相關的上下文？」

非常好！讓我們把圖修正得更精確，並反映你的需求：**(6) LLM → (RESPONSE) → (7) CODE → (ANSWER) → (8) CHAT**

```
┌──────────────┐
│    (1)       │
│    CHAT      │
│  使用者提問   │
└─────┬────────┘
      │
      │ QUESTION
      ▼
┌──────────────┐
│    (2)       │
│     CODE     │
│ 處理問題邏輯  │
└─────┬────────┘
      │
      │ (3) RETRIEVE
      ▼
┌──────────────┐
│    (4)       │ **KNOWLEDGE BASE**
│ KNOWLEDGE    │
│    BASE      │
│  知識庫檢索   │
└─────┬────────┘
      │
      │ 回傳背景資料
      ▼
┌──────────────┐
│    (5)       │
│     CODE     │
│ 組成 PROMPT  │
└─────┬────────┘
      │
      │ PROMPT
      ▼
┌──────────────┐
│    (6)       │
│     LLM      │
│  大型語言模型 │
└─────┬────────┘
      │
      │ RESPONSE
      ▼
┌──────────────┐
│    (7)       │
│     CODE     │
│ 整理回應產生  │
│   ANSWER     │
└─────┬────────┘
      │
      │ ANSWER
      ▼
┌──────────────┐
│    (8)       │
│    CHAT      │
│ 顯示給使用者  │
└──────────────┘
```

## 流程順序簡述

- ① 使用者在 **Chat** 輸入問題 →
- ② **Code** 接收問題 →
- ③ 如有需要，向 **Knowledge Base** 檢索資料 →
- ④ **Knowledge Base** 回傳背景資料 →
- ⑤ **Code** 將問題 + 背景資料組成 Prompt →
- ⑥ 將 Prompt 傳給 **LLM** →
- ⑦ **LLM** 回傳回應 →
- ⑧ **Code** 將答案送回 **Chat** 顯示給使用者

---

#### 大概念：語義向量空間 編碼型 LLM(Encoding LLM, Vector Database)

再來談 RAG 的大概念：

這個概念涉及一種不同類型的模型，叫做 **編碼型 LLM（Encoding LLM）**。

這種模型與我們熟悉的「**預測下一個 token**」的 LLM 不同。

* 預測型 LLM：根據上下文預測接下來的文字
* 編碼型 LLM：把一段資訊轉換成**數字向量**（vector）

舉例來說，編碼型 LLM 輸入一段文字，輸出一組數字（向量），而這組數字在某種程度上能代表文字的意思。

那什麼叫「一堆數字代表意思」呢？

意思是：如果有兩段文字，內容意思相近，那它們所對應的向量就會彼此很接近。

想像一下：

* 如果這些向量有三個維度，就可以看成是三維空間的座標點（X、Y、Z）
* 如果你把很多段文字都映射到空間裡，那些彼此靠近的點，就代表內容意思相似

這裡講的「意思相似」，不是指文字一樣，而是指它們在語意上是**相近的概念或主題**。

編碼型 LLM 不只輸出三個數字，通常會輸出幾百、甚至幾千個數字，代表在多維空間中的一個點。

雖然聽起來很科幻，但你只要記住：**向量彼此距離越近，表示語意越相近。**

**Encoding LLM** 的強大之處：
✅ 不看字面
✅ 看語意

---

### RAG 的運作流程

那麼，這跟現實有什麼關係呢？

例如使用者問：「飛往倫敦的機票價格是多少？」

如果單純依賴程式碼去比對「London」這個字，其實很脆弱。

因為使用者也可能問：「飛往英國首都的機票多少？」或者「我要去希思羅機場，票價多少？」

這些問題的意思是相同的，但字眼完全不同。

這就不是簡單的關鍵字比對可以解決的。

於是我們可以運用編碼型 LLM 的技巧：

* 把使用者的問題轉換成向量
* 同時把整個資料庫（知識庫 Knowledge Base）拆成小段落
* 每段落都送進編碼型 LLM，取得它的向量表示
* 接著比對向量距離，找出最接近的段落

找到相關段落後，就把這些段落的文字，一起放進 Prompt 中，送給 LLM 處理。

例如：

> 使用者問：「我要測試我的 App，需要使用 Gmail，但連 mail.google.com 都顯示拒絕訪問」

如果沒有背景資料，ChatGPT 只能回答一些通用建議，例如檢查網路。

但如果我們加上背景資料：

* 公司政策不允許員工使用私人信箱
* 如果看到「拒絕訪問」錯誤，可能是公司防火牆造成

這時 ChatGPT 就能針對背景資訊給出更精準的回覆，告訴使用者該如何申請權限。

這就是 **RAG 的精髓**：從知識庫中挑選出有用的上下文，放進 Prompt 中。

---

#### RAG 正確流程如下：

> - 使用者的問題會先轉成**向量**，
> - 再用向量去向**向量資料庫**(Vector Database)檢索相關資訊，
> - 然後把**檢索到的文字片段**加上**問題**一起組成 Prompt，
> - 最後送Prompt給 LLM 產生答案。

---

### 為什麼不直接把全部資料都放進 Prompt 呢？

有人可能會問：

> 為什麼不乾脆把整個知識庫一次丟給 LLM？

原因有三：

1. 大部分公司的資料庫非常龐大，遠超過 LLM 能一次處理的 **Token 限制**
2. 一次丟進太多資料，會分散模型注意力，反而**降低回答品質**
3. 每次呼叫都丟大量內容，效率低且成本高

因此，RAG 的精髓就是：
✅ 精準挑選最相關的上下文
✅ 確保回覆精確、符合需求
✅ 無須重新訓練整個模型

這就是 RAG (Retrieval-Augmented Generation) 成功的關鍵。

⭐ RAG 的全名
- R → Retrieval
- A → Augmented（增強的）
- G → Generation（生成）

---

## 微調（Fine-Tuning）

接著，稍微談談 **微調（Fine-Tuning）**。

微調是在 **訓練階段** 加入額外資料，讓模型學會新的技能或專業知識。

但這是一個**高度研發（R&D）**的領域，具有以下特點：

* 結果不保證，需要實驗才能知道效果
* 訓練成本高，需要大量矩陣運算（matrix calculations）
* 要有大量 **專有數據**（proprietary data），包含想學習的 prompt 和回答
* 訓練過程昂貴，往往需要 GPU 叢集運算

為什麼是 **GPU** 呢？
因為訓練 LLM 涉及大量矩陣相乘，而 GPU 正是為了遊戲而設計出來做這種高速並行運算的硬體。

---

### 微調的風險與回報

微調是一場 **高風險、高報酬** 的賭注：

* 可能投資大量資源，卻發現效果有限
* 也可能打造出一個遠勝 GPT-4 的小型模型，對特定商業任務有極致優勢

例如：

* 在電商專案中，模型學會根據產品描述**預測價格**
* 不只是記憶訓練數據，而是真正學會如何推估未知產品的價值

這是 **RAG** 做不到的事。
**RAG** 永遠只能回答你已有的資料。
但微調能讓模型 **泛化（generalize）**，學會新技能。

微調後的模型在推理階段也更快，因為不必每次都做向量檢索、再加 context，一切都已內化到模型權重中。

---

## RAG vs Fine-Tuning — 如何選擇？

總結兩者差異：

| 特性   | RAG             | 微調 (Fine-Tuning) |
| ---- | --------------- | ---------------- |
| 資料使用 | 使用現有資料庫，動態加入上下文 | 在**訓練階段融入新知識**       |
| 成本   | 成本低，不需再訓練模型     | **成本高**，需要大量運算資源     |
| 泛化能力 | 只能回答**現有資料庫**的內容    | 可學習新技能並泛化到新情境    |
| 推理速度 | 需要檢索再加上下文，**稍慢**    | **推理快**，所有知識已在模型裡    |

大致判斷原則：

* **RAG** → 當你擁有**現成的知識庫**，需要讓 AI 學會精確回答特定資訊
* **微調** → 當你想讓 **AI 學習新技能、理解新概念**，而不是只背現成資料

但其實這不是非此即彼。很多時候可以 **兩者並用**，同時受益於知識庫和微調模型的優勢。

重點在於：你要願意投入 **R&D**，持續試驗，找到**最適合**你的商業場景的組合。

---

## AI Agents vs Workflows：理解自主系統

### AI Agents

不僅 AI Agents 現在非常火熱，而且它們也是我最喜歡討論的主題之一，因此我非常期待這一講。

首先，必須先說明一點：目前對「什麼是 Agent」仍存在一些混淆和不確定性。如今，「AI Agents」這個詞被用來描述許多不同的概念。

就我個人而言，我很喜歡 Hugging Face 這家 AI 公司提出的一個簡潔而精確的定義：

> **🤖 AI Agent 是由 LLM 控制工作流程的程式。**
> 也就是說，**LLM 的輸出決定了接下來要做什麼。**

這個定義非常清楚，也是我最喜歡的。不過，值得注意的是，許多人所謂的「Agentic 系統」或「在使用 Agents」通常會指以下五種情況之一，或是同時包含多種：

1. **多次 LLM 呼叫**
   不再只是呼叫一次 LLM（像傳統聊天機器人那樣），而是多次呼叫，彼此串聯，形成連續的流程。

2. **工具使用（Tool Use）**
   這是一個非常有趣的概念，指讓像 ChatGPT 這樣的 LLM 可以**執行程式碼**、打開瀏覽器、查詢資料等。你賦予 LLM 工具，它就能運用這些工具完成任務或回應提示。聽起來很神祕，好像 GPT 能「伸手進」你的電腦。實際上沒那麼神奇，等我解釋完，你可能會覺得：「哦，原來只是這樣啊！」雖然多少有點失落，但暫時就先把它當作魔法吧。

3. **LLMs 之間的互動**
   有些人認為，只要在系統中，不同的 LLM 彼此能互相傳遞訊息，就構成一種 **Agentic 系統**。

4. **規劃者（Planner）協調 LLM**
   指有一個「規劃者」的 LLM，專門負責協調其他 LLM 的動作。對部分人來說，這也是 Agentic 平台的一種定義。

5. **自主性（Autonomy）**
   這是最抽象、也最難定義的一種狀況。有人認為，只要一個 LLM 平台具備一定程度的自主性，也就是能自己**決定接下來要做什麼**，那就算是 Agentic 系統。例如，我之前展示過的 Operator Agent 就非常具備這種自主性，完全屬於 Agentic 平台的範例。

---

### Agentic 系統 (Agentic System)

Anthropic 提出了一個非常清晰且實用的方式，來描述 Agentic 系統的兩種類別：

* **Workflows** → 屬於「流程型」系統，LLMs 與工具透過預先定義好的程式邏輯（predefined code paths）被編排，執行步驟通常是固定且可預測的。
* **Agents** → 屬於「自主型」系統，LLMs 能夠動態決定接下來的動作，如何運用工具，自主掌控完成任務的方式，具備更高的彈性與自主性。

因此，整個 Agentic 系統的範疇，確實同時涵蓋了 Workflows 與 Agents 這兩種型態。

#### 🔗 Workflows（工作流程）

指系統中，LLMs 執行一系列預定任務。通常一個較大的任務會被拆解成多個小步驟，由不同的 LLM 分別執行，但流程是事先設計好的。許多人仍會將這種系統稱為 Agentic，或認為其中存在 Agents，因為它牽涉到任務拆解。但 Anthropic 認為，這其實是 Workflow，而不是真正的 Agent。

#### 🤖 Agents（代理）

相對而言，Agents 能夠**動態決定下一步要做什麼**。這就是「選擇你自己的冒險」的場景。LLMs 會根據不同情況以不同順序被呼叫，自行決定如何完成任務，並掌控執行過程。這就是 Agent 型的 Agentic 系統。

---

#### 三種 Workflow 範例

以下提供三個實際可用的 Workflow 範例，讓你思考如何應用在你的業務領域中：

✅ **Prompt Chaining（提示串接）**
如字面意思，就是先執行一個提示，完成一個動作，再接著下一個提示，完成另一個動作。通常你已經預先決定要完成某個任務，並拆解成多個具體步驟，針對每個步驟分別呼叫 LLM。

✅ **Routing（路由）**
指利用 LLM 決定該呼叫哪個不同的 LLM。舉例來說，客戶提出問題，先用一個 LLM 判斷問題的類型：只是需要查詢資料？需要接真人客服？或是想訂閱電子報？根據判斷結果再交給適合的 LLM 處理。

✅ **Evaluator-Optimizer（評估-優化器）**
這是非常常見的模式，用來確保回覆品質。如果你非常重視 LLM 回答的準確度、機密保護，或避免模型被誤導，那通常會使用這種模式。做法是：先由一個 LLM 產生回答，再由另一個 LLM 審核檢查回答是否符合規範；若不符合，就退回重答，或由另一個 LLM 產生拒答訊息。這種模式被稱作 Evaluator-Optimizer，非常常見。

```
┌─────────┐       ┌────────────────────┐      ┌────────────────────┐      ┌─────────┐
│  Input  │ ──▶  │ LLM Call Generator │ ──▶ │  LLM Call Evaluator │ ──▶ │ Output  │
└─────────┘       └────────────────────┘      └────────────────────┘      └─────────┘
                        ▲                             │
                        │                             │
                        │      Rejected + Feedback    │
                        └─────────────────────────────┘
```

---

#### Agents 

相比 Workflow，**Agents** 不受固定流程限制：

* Agents 是**開放式**的，沒有固定的執行路徑，而是由 Agent 自行決定如何合作、如何執行任務。
* 存在 **feedback loops（回饋迴圈）**，也就是 Agent 可以不斷重複呼叫自身，直到產生滿意的結果。
* **執行路徑不可預測**，因此也帶來測試上的挑戰。因為你無法確定流程會怎麼走、需要多少時間完成，也不清楚具體執行步驟。我們會在第三單元深入討論這些測試挑戰。

---

### 解密 Tool Use 的魔法

接下來，讓我們揭開所謂「Tool Use」的真相。

理論上，Tool Use（也稱 Function Calling），是讓 LLM 可以執行像查詢資料庫、呼叫其他 LLM、在電腦上執行程式碼等操作。聽起來像 GPT 能伸手進你的電腦做事，但實際上並沒那麼神奇。

實際流程如下：

* 你的程式會傳送一個 Prompt 給 LLM，告訴它你能做什麼（例如「我能查資料庫，但你需要這樣告訴我」）。
* LLM 回覆告訴你它想做什麼。
* 程式真正執行那個動作（例如查詢機票價格），再把結果傳回 LLM。
* 最後，LLM 根據查詢結果產生最終回覆。

```
                 ┌───────────┐      PROMPT      ┌───────────┐
                 │           │ ───────────────▶ │           │
                 │    CODE   │                  │    LLM    │
                 │           │ ◀─────────────── │           │
                 └───────────┘     RESPONSE     └───────────┘
                      ▲ 
                      │
                  EXECUTE
                      │
                      ▼
                 ┌───────────┐
                 │   Tools   │
                 │  SYSTEM   │
                 │ (Computer)│
                 │           │
                 └───────────┘
```

本質上，就是程式裡的 if 判斷：

> 如果 LLM 說「我要查詢機票價格」，那程式就去查，再把結果交給 LLM。

沒有什麼魔法，全部都只是 **Prompting** 加上 **程式邏輯**。

---

舉個簡單範例：

```
You are a support agent for an airline.
You answer a user's question.
You also have the ability to query ticket prices.
Just respond: Use tool to fetch ticket price for London.

User's question: I'd like to go to Paris. How much is a flight?
```

ChatGPT 的回覆通常是：

> Use tool to fetch ticket price for Paris.

這就是 Tool Use 在實務上的運作方式。毫無神秘，就是在 Prompt 裡明確告訴 LLM 它能做什麼，以及它該如何告訴你想做什麼。

---

### 常見的 Agents 範例

你可能也看過一些 Agents，例如：

* **Operator Agent**（OpenAI）
  高度自主性，我在課程開頭展示過。
* **Deep Research（OpenAI）**
  我經常使用，也會在課程裡一起操作，非常強大。
* **Manus**（中國新創公司） [https://manus.im/](https://manus.im/)
  在新聞中常被提及，能從零開始建立完整網站、搜尋舊金山的公寓資料等，非常驚人。他們利用現成的 Frontier Models（如 Anthropic 的 **Claude** 和阿里雲的 **Qwen**），獨特之處在於利用 Inference-Time optimization 協調多次呼叫 LLM。

---

### Agent Frameworks

當你要實作 Agents，你的團隊會面臨是否使用 Agent Framework 的決策。這有點類似 **Buy vs. Build**（買現成或自行開發）。

Agent Frameworks 的選擇從「功能齊全」到「極輕量」都有：

* **AutoGen**（Microsoft）
* **LangGraph**（LangChain 團隊推出）
* **Crew AI**（輕巧靈活，我個人非常喜歡）
* **OpenAI Agents SDK**（非常輕量，主要用來快速串接多次 LLM 呼叫並提供 **Guardrails**）
* **Native 自行撰寫程式**，由你的工程團隊自行串接各種 LLM。Anthropic 曾在一篇極具影響力的部落格中，強烈推薦這種方式，認為它能給開發者**最細緻的掌控權**。

---

#### Agent Frameworks 的風險與控管

Agent Frameworks 雖然極具威力，能解決複雜的商業問題，但也伴隨以下風險：

* **決策路徑不可預測**
* **輸出結果可能不可預測**，可能無法達成商業目標。
* **運行成本不易掌控**，尤其是遇到 feedback loops 時，可能造成推理成本暴增，消耗大量運算資源。

降低風險的方法有兩個：

1. **監控（Monitoring）**
   必須有完善的監控工具。例如 LangGraph 搭配 LambSmith，可監控 Agents 的整個互動過程。

2. **Guardrails（防護欄）**
   在程式中設下限制，規範 LLM 可以做什麼。說穿了，所謂 autonomy，本質上就是一連串 **if 判斷**。你的技術團隊能決定模型允許做哪些動作，並即時檢查是否合理、是否有授權、是否超過預算。

正如 OpenAI Agents SDK 所說：

> Guardrails 能確保你的 Agents 行為安全、一致，並遵守你所設下的邊界。

---

以上，就是關於 Agents 的完整介紹！雖然花了不少時間討論，但希望你覺得物超所值。我自己非常享受這部分的內容。雖然目前著重在解決方案面，但別擔心，我們接下來還會討論更多實際應用中會遇到的挑戰，以及如何將 Agents 真正導入你的業務場景。

接下來，我想和你聊聊，該如何與公司裡的其他團隊合作，協力做出技術決策，並支持 AI 專案的成功部署。

---

## AI Decision-Making: 跨部門協作的技術決策

如果你一直在納悶，為什麼最近要深入探討像 RAG、Agents 等技術細節，那麼現在答案揭曉了。因為接下來我們要談的是：**作為一名經理人、領導者、創業者或高階主管，你該如何運用這些知識，做出關鍵的商業決策**。

---

### AI 專案常見的決策課題

那麼，在 AI 專案裡，通常會面臨哪些決策呢？

#### **選擇使用哪種模型**

最基礎的問題就是「**該用哪種模型？**」在第一單元裡，我們已介紹過各種模型類型，而在選擇上通常需要考慮：

* **要用開源還是商用付費模型？**
* 模型該選擇多大的規模？
* 如果你準備實作 RAG 流程，就還得決定要使用哪種類型的 Encoder 模型。

---

#### AI 解決方案的優化方式

除了模型選擇之外，還有各種 AI 解決方案的優化技術，例如：

* **微調（Fine-tuning）**
* **Agents**
* **RAG**

每種方式都有其優缺點。

你可能會想：**「這些技術決策，交給技術團隊處理不就好了嗎？」**

答案是：**不行。**
因為這些技術選擇會帶來**商業層面**的**重大影響**。作為領導者，你必須親自參與討論，並與技術團隊、資料科學團隊以及其他部門一起**協作決策**。

---

### AI 專案的決策流程

在第三單元，我們會談到**如何完整推動大型 AI 專案，或是打造一間 AI 公司**的端到端流程。不過在本單元，我們先專注於其中一個核心環節：**如何做出這些關鍵技術決策**。

---

#### 科學導向（Science-led）的決策方式

我建議採用一種科學導向的決策流程，也就是：**像科學家一樣行事。**
流程包括以下步驟：

1. **建立小型資料集**
   先建立一個精簡的資料集，用來進行快速實驗。

2. **設計商業指標**
   設計出衡量成效的指標，以判斷 AI 解決方案是否有達到提升。

3. **進行原型測試**
   不論是測試不同模型，還是不同技術（例如嘗試 RAG 或 Fine-tuning），都應先做原型實驗。

4. **評估影響、成本與風險**
   測量各種選項的成本，包括訓練成本、推理（inference）成本，並評估潛在風險。

5. **持續反覆測試**
   這是實驗性且持續迭代的過程。透過多次小規模測試，對比不同方法與模型，協助做出最適決策。

---

我特別強調這一點，因為 AI 專案常常需要 **心態上的轉變**。
資料科學團隊本就習慣採取科學方法進行實驗，但其他部門若要成功參與 AI 專案，也必須接受這種科學導向的思維。

AI 專案與傳統軟體或業務專案的不同，在於：

> **AI 專案一開始往往無法完全預測最終成果。**
> 因此，整個組織都必須具備「研究者的心態」，勇於嘗試實驗，也能接受短期內看不到確定結果的不確定性。

---

#### 科學導向決策流程示意圖

```
┌─────────────────────┐
│  Build a small      │
│  dataset            │
└─────────┬───────────┘
          │
          ▼
┌──────────────────────────┐
│  Develop a business      │
│  metric                  │
└─────────┬────────────────┘
          │
          ▼
┌─────────────────────────────┐
│  Prototype a model or       │◀──────────┐
│  technique                  │            │
└─────────┬───────────────────┘            │
          │                                │
          ▼                                │
┌────────────────────────────┐             │
│  Assess impact, costs,     │─────────────┘
│  risks                     │
└────────────────────────────┘
```

---

### 決策需要哪些人參與？

答案很簡單：**幾乎所有人。**

這是一個必須跨部門協作的過程。即使這些決策看起來極度技術導向，背後往往涉及多方利害關係人。

---

#### Obvious Stakeholders（主要利害關係人）

* 高層領導（你自己）
* 資料科學團隊
* 工程團隊（例如建構 RAG 流程）
* 產品團隊（理解產品功能、影響）
* 營運團隊
* 銷售與行銷團隊
* 財務團隊（因不同選擇將影響產品的單位經濟成本）

---

#### Equally Important Stakeholders（同樣重要的利害關係人）

除此之外，還有一些部門雖然不直接參與技術建置，但同樣深受影響，也需要被納入討論：

* 法務與合規部門（特別關心偏見、可解釋性等議題）
* 客戶服務團隊
* 資訊安全與風險管理團隊
  尤其當你打算採用商業付費模型時，就意味著數據可能會送到第三方（例如 OpenAI）。雖然 OpenAI 對資料有一定保護承諾，但仍需資安團隊審視相關風險。有些企業甚至會完全禁止資料外流，此時就必須考慮使用開源模型，並在內部或私有雲環境中部署。
* 人資或營運團隊（若專案將影響人才需求或技能布局）
* 道德與負責任 AI 團隊（若公司有設立此專責部門）
* 風險管理團隊
* 客戶體驗（CX）及使用者體驗（UX）團隊
* 治理與稽核團隊

---

當然，每間公司都不同。以上名單僅供參考，目的是幫助你思考：**誰該被邀請到決策桌上？**

如果你在初創公司或小規模公司，可能會想：「我們公司就三個人，哪來這麼多部門？」

即便如此，這三個人往往同時扮演多種角色。因此，即使不需要 20 人開會，你還是必須確保有人能站在各種角度思考，例如支援、資訊安全、法遵等。**每個角色都重要，都該在決策過程中被納入考量。**

---

### 更多具體決策範例

除了前述的大方向決策，還有許多看似細節、卻與商業息息相關的技術選擇，例如：

---

#### 託管式 AI 服務（Managed AI Provider）

指的是由雲端服務商代管所有對其他模型的呼叫，例如：

* Amazon Bedrock
* Google Vertex AI
* Microsoft Azure AI

雖然這類決策多由工程團隊主導，但對資安、合規性及商業策略都有潛在影響，其他部門也必須參與討論。

---

#### 抽象層（Abstraction Layers）的使用

若你要打造一個 Agentic 框架，你會選用 Crew？LangGraph？還是自行開發？
若是建立 RAG，你會使用 LangChain 還是自己寫？

這某種程度上就是 **Build vs. Buy** 的抉擇，同樣需要跨部門審慎討論。

---

#### 向量資料庫（Vector Data Store）的選擇

在使用 RAG 時，勢必會遇到向量資料庫的挑選問題。
雖然這聽起來非常技術導向，但實際上它會影響：

* 產品能否實現某些功能
* 系統效能、擴展性、可靠性及容量規劃

---

希望你已經感受到，**這些討論絕對不能缺席**。

幸運的是，我已準備了一套工具（Toolkit），幫助你推動這些跨部門對話。我們將在下一堂課一起深入探討這套 Toolkit！

---

## AI 決策制定工具包

**Section2 Framework for Cross Functional Decisions in Gen AI.xlsx**

現在，是時候用第二個工具包，為第二單元畫下句點了。

這個工具包就是為了協助你推動 **AI 決策制定** 而設計的。

先來說說它是什麼，以及它不是什麼。

---

### 工具包是什麼？

這是一個 **框架**，用來協助討論 AI 領域裡面那些攸關全局的重要決策。

AI 專案跟一般專案不一樣，它需要跨部門的協作。這個工具包的目的：

- ✅ **確保對的人在場** — 把所有該參與討論的利害關係人都納進來。
- ✅ **涵蓋對的議題** — 避免遺漏任何關鍵面向。
- ✅ **建立實驗性文化** — 培養「**科研優先** (science-first)」的思維，讓組織能像科研機構一樣，勇於實驗、接受不確定。

---

### 工具包不是什麼？

同時，也必須強調它 **不是以下這些**：

- ❌ **硬性規定** — 不一定完全適合每個組織，也不一定需要照表操課使用。
- ❌ **萬靈丹** — 並不是所有決策都必須遵循同一個流程。
- ❌ **所有技術決策清單** — 真正要討論哪些技術細節，還是要由你的工程、AI 或資料科學團隊來提出。

簡而言之，這是一個 **指引**，而不是教條。

---

在上一講中，我們談過「實驗式的方法」來評估各種決策。不論你是在《財星 500 大企業》，還是只有一個人的初創公司，**敢於嘗試、反覆驗證的心態**，都是成功推動 AI 專案的關鍵。

---

### 工具包長什麼樣？

揭開工具包的真面目：

它同樣是一個 Google Sheet，連結會放在課程資源區。

簡單來說，它包含兩個部分：

✅ **人員清單**
- → 表格頂端列出參與決策討論的潛在利害關係人。
- → 不一定是實體會議，也可以是 Slack 頻道、Email 討論串。
- → 請把它當成初步的 checklist，幫助你檢查：是否所有該出席的人都到齊。

✅ **議題清單**
- → 表格下方有區塊讓你填寫目前使用的資料集，以及評估成效的指標 (metrics)。
- → 指標可能不只一個，也可能有多組資料集，目的是釐清思路，而不是告訴你該怎麼做。

---

表格本身提供了許多範例，幫助你理解怎麼列出不同決策。

它和第一單元的工具包有個主要差異：

* **第一單元** → 每個專案或商業計劃需要建立獨立工作表。
* **第二單元** → 所有決策都可以放在同一張表的不同列。

因此，這張表可以一次比較多個選項，例如：

* 第一區塊 → 不同模型的選擇
* 第二區塊 → 各種優化技術（如 RAG、Agentic AI）
* 第三區塊 → 更細節的技術選擇（例如資料庫類型等）

---

看橫向的欄位（columns），大致會看到以下幾項：

✅ **成本 (Costs)**
→ 包括一次性的前期成本（如訓練、建置架構），以及持續性的運行成本（如推理費用、API 費用）。

✅ **效益 (Benefits)**
→ 不只有金錢效益，也包括其他無形的價值，例如更好的客戶體驗、創新的商業模式。

✅ **風險 (Risks)**
→ 表格裡非常重要的一區。
→ 促進不同部門提出各自掌握的風險、討論風險嚴重性，並將觀點納入決策。
→ 特別是資訊風險、法務、合規等部門，需要在這裡貢獻意見。
→ 每個格子 (cell) 都可紀錄已辨識的風險，以及擬定的對策 (mitigations)。

✅ **決策建議 (Recommendation)**
→ 最右側欄位，用來紀錄團隊的決策共識：

* 是否採取這項方案？
* 是否需要再做更多實驗？
  → 在部分欄位的欄頭上，我也放了一些範例，提示哪些角色可能負責填寫該欄位。

---

再次提醒，請把這張表 **視為「引導思考的工具」**，而不是一個絕對精確的科學模型。

它的目的是 **促進跨部門討論**，而不是取代專業判斷。

無論是大企業、中型企業，還是只有你一人的初創公司，都能運用這張表。即便你是一位孤軍奮戰的創業家，也能透過這張表練習：戴上各種不同部門的思維帽，從多角度來思考問題。

---

### 這樣做還有什麼額外好處？

這種跨部門決策過程，還會帶來以下額外好處：

✅ **🎓 教育全體團隊**
- → 幫助跨部門同事真正了解 AI 的優勢與潛在風險。
- → 推動一種心態轉變，例如關注倫理風險、可解釋性 (explainability) 等議題。
- → 嚴謹的過程能確保每個人都對 AI 的風險有共識。

✅ **🛰️ 清楚傳達各種取捨 Trade-off**
- → 如果你選擇採用 frontier models（例如封閉式大型語言模型），大家就能理解這意味著什麼：

   * 未來可能有些事情無法實現
   * 數據可能外流到第三方
   * 在某些層面失去彈性
    → 這有助於獲得團隊支持與共識。

✅ **👍 提前因應組織變動 Buy-in**
→ 特別是當 AI 專案會影響到公司內部需要哪些新技能、或必須調整組織結構時，愈早取得共識，愈能順利推動變革。

---

### Non-dollar benefits 是什麼？

✅ **Non-dollar benefits** → 無法用金額直接衡量的好處，例如：

* 提升用戶滿意度
* 縮短回應時間
* 提高品牌形象
* 確保合規或降低法律風險
* 強化資料安全
* 提升產品競爭力（差異化）
* 提升員工工作滿意度或效率
* 加快市場反應速度（Time to Market）

---

這就是本單元的總結！

希望你已經認同這個模板，以及這種決策過程的重要性。

最重要的是：

> AI 項目的成功，不只是技術問題，而是需要整個組織一起擁有「**科研優先 (science-first)**」的心態與文化。

而這些工具，就是幫助你實現這一點的最佳途徑。

接下來，就要進入最大的、最精彩的單元——
**如何成為 AI 領導者！** 🚀

你已經學會如何成為策略家，也懂得如何做出科學導向的決策。
接下來，要讓你成為一名能在不確定中領導團隊、成功交付 AI 專案、創造可驗證投資報酬率的領導者。

讓我們繼續前進！

---
