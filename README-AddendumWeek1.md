# Agents AI

## Week 1 Day 1
---
### Startup
Flexible AI workflow automation https://n8n.io/

- **n8n.io** is a **low-code/no-code** workflow automation platform that allows users to create workflows by orchestrating between different applications without needing extensive coding knowledge.

- https://github.com/n8n-io/n8n
- Install n8n locally
    ```cmd
    npx n8n
    ```
- http://localhost:5678/home/workflows
- Set up your **.env** file with your **N8N_API_KEY** 

    ```note
    .env
    N8N_API_KEY=eyJh...

    ```

### Week 1 to Week 6 learning roadmap:

* **ğŸŸ¤ Dark Coffee = Theory/Concepts**
* **ğŸ”µ Blue = Frameworks/Hands-on Implementations**
* **ğŸŸ¡ Gold = Projects/Applied Use Cases**

---

### âœ… **Week 1: Foundations**

ğŸŸ¤ Make an Agentic Workflow
ğŸŸ¤ Agents and Agentic Patterns
ğŸŸ¤ Orchestrating LLMs
ğŸŸ¤ Autonomy and Tools
ğŸŸ¡ **Project 1:** Your Personal Career Agent

---

### âœ… **Week 2: OpenAI Agents SDK**

ğŸŸ¤ Understand **OpenAI Agents SDK** Concepts
ğŸŸ¡ **Project 2:** an SDR
ğŸ”µ Tools vs Agents Guardrails
ğŸŸ¡ **Project 3:** Deep Research
ğŸŸ¡ **Project 3:** Deep Research App

---

### âœ… **Week 3: CrewAI**

ğŸŸ¤ Understand **Crew AI** Concepts
ğŸ”µ Build a Crew Agent
ğŸŸ¡ **Project 4:** Stock Picker
ğŸŸ¡ **Project 5:** Developer Agent
ğŸŸ¡ **Project 5:** Engineering Team

---

### âœ… **Week 4: LangGraph**

ğŸŸ¤ Understand **LangGraph** Concepts
ğŸ”µ Build a LangGraph Agent
ğŸ”µ Tools, Memory, Web Searches
ğŸŸ¡ **Project 6:** Sidekick
ğŸŸ¡ **Project 6:** Sidekick Improvements

---

### âœ… **Week 5: AutoGen**

ğŸŸ¤ Understand **AutoGen** Concepts
ğŸ”µ AutoGen Agent Chat
ğŸ”µ AutoGen Core
ğŸ”µ AutoGen Core - Distributed
ğŸŸ¡ **Project 7:** Agent Creator

---

### âœ… **Week 6: MCP (Multi-Agent Control Protocol)**

ğŸŸ¤ Agentic Architecture and MCP
ğŸ”µ Building an MCP Server and Client
ğŸ”µ Multiple Local and Remote MCP Servers
ğŸŸ¡ **Project 8:** AI Equity Traders
ğŸŸ¡ **Project 8:** AI Equity Traders in Action

---

This format visually distinguishes **what youâ€™re learning (theory), how youâ€™re building (frameworks), and where youâ€™re applying it (projects)**â€”making it easier to track your progression from understanding to implementation to real-world use.

Based on your provided transcript and image, hereâ€™s a **summary of Projects 5 through 8** along with their significance, tone, and learning objectives:

---

### ğŸŸ¡ **Project 5: Engineering Team** å·¥ç¨‹åœ˜éšŠæ¨¡æ“¬å™¨

> **"An agentic platform representing a real engineering team."**
ã€Œæ¨¡æ“¬ä¸€å€‹çœŸå¯¦è»Ÿé«”é–‹ç™¼åœ˜éšŠçš„ä»£ç†äººå¹³å°ã€

* Simulates collaboration between agents playing specific engineering roles:

  * Frontend Developer
  * Backend Developer
  * Engineering Lead
  * Tester
* These agents **collaborate to build real software**, like a functioning backend system.
* **Learning focus:** how to model **role-based autonomy** and **multi-agent collaboration** for real-world engineering use cases.
* **Real twist:** The platform built by this team is reused in Project 8â€™s financial simulation.

---

### ğŸŸ¡ **Project 6: Sidekick** å´é‚ŠåŠ©æ‰‹

> **"A browser-controlling co-pilot agent on your desktop."**
ã€Œèƒ½èˆ‡ä½ ä¸€èµ·åœ¨æ¡Œé¢ä¸Šäº’å‹•çš„ AI ç€è¦½å™¨å‰¯é§•é§›ã€

* This agent runs **alongside you**, with **interactive control over your browser**.
* Inspired by Chinese platform **Manus**, but unlike cloud-based agents, this one runs locally.
* You can **co-browse, automate clicks, scrape, search, and interact** with websites.
* **Learning focus:** real-time agent interaction and shared control â€” building an **AI copilot** you can work with side by side.

---

### ğŸŸ¡ **Project 7: Agent Creator** ä»£ç†äººç”Ÿæˆå™¨

> **"An agent that generates agents."**
ã€Œæœƒè‡ªå·±ç”¢ç”Ÿä»£ç†äººçš„ä»£ç†äººã€

* You build a **meta-agent**, an agentic framework that can **spawn new agents**.
* These generated agents will perform commercial tasks.
* Not heavily commercial itself, but **highly educational and intellectually rich**.
* **Learning focus:** recursive agent design, self-generating frameworks, and tooling automation.

---

### ğŸŸ¡ **Project 8: AI Equity Traders** AI è‚¡å¸‚äº¤æ˜“å“¡

> **"Capstone: autonomous agents that trade in financial markets."**
ã€Œå£“è»¸å°ˆæ¡ˆï¼šé‡‘èå¸‚å ´çš„å¤šä»£ç†äººäº¤æ˜“æ¨¡æ“¬ã€

* Agents perform financial research by:

  * Reading stock prices
  * Analyzing real-time financial news
  * Parsing SEC filings & annual reports
  * Making buy/sell decisions
* Simulates trading accounts, **tracks P\&L**, and evolves over time.
* **Bonus detail:** the trading platform is actually written by agents from **Project 5**.
**  ç³»çµ±æœƒæ¨¡æ“¬å¸³æˆ¶é¤˜é¡ã€ç›ˆè™§ç‹€æ…‹ç­‰ï¼Œä¸¦ä½¿ç”¨ç¬¬ 5 å°ˆæ¡ˆé–‹ç™¼çš„å¾Œå°ç³»çµ±ä½œç‚ºäº¤æ˜“å¹³å°ã€‚

* **Learning focus:** real-time multi-agent autonomy, retrieval-augmented workflows, financial simulation.
** å­¸ç¿’é‡é»ï¼š å¯¦ä½œçœŸæ­£ã€Œè‡ªä¸»æ±ºç­–å‹ã€çš„å¤šä»£ç†äººç³»çµ±ï¼Œæ‡‰ç”¨åœ¨çœŸå¯¦ä¸–ç•Œçš„å•†æ¥­é‚è¼¯ï¼ˆé‡‘èç§‘æŠ€å ´æ™¯ï¼‰ã€‚
---

### ğŸ§  Why They Matter

The instructor emphasizes that **Projects 5â€“8 are the most exciting and commercially valuable**:

* They combine deep **LLM agentic theory** with **hands-on, applied systems**
* They model **real-world B2B/B2C use cases**: software teams, copilots, agent factories, fintech traders
* Youâ€™ll build **reusable infrastructure** that mirrors production-level AI agent systems

---

### Setting Up Your Environment
- GitHub repository:
    ```note
    git clone https://www.github.com/christseng89/agents-ai.git
    ```
- Install UV
    ```note
    powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
    uv --version
        uv 0.7.9 (13a86a23b 2025-05-30)
    uv sync
        pyproject.toml
    uv pip install jupyterlab 
    uv run jupyter lab 
    ```
- Create .env
    ```note
    GOOGLE_API_KEY=xxxx
    ANTHROPIC_API_KEY=xxxx
    DEEPSEEK_API_KEY=xxxx
    ```

- Jupyter Lab URL:
    ```note
    http://localhost:8888/lab/tree/1_foundations/1_lab1.ipynb
    ```

- Using **VSC** to run Jupyter Lab:
    - Open 1_foundations/1_lab1.ipynb
    - Select the Python kernel (.venv\Python 3.12.10) in the top right corner
    - Run the cells in the notebook

## Week 1 Day 2
---
### What is an AI Agent?
#### ğŸŸ¤ é—œæ–¼ AI ä»£ç†äººï¼ˆAgentï¼‰çš„å®šç¾©æ¨¡ç³Šæ€§
> **"AI Agents are programs where LLM outputs control the workflow."**
ã€ŒAI ä»£ç†äººæ˜¯æŒ‡ç”± LLM è¼¸å‡ºä¾†æ§åˆ¶å·¥ä½œæµç¨‹çš„ç¨‹å¼ã€‚ã€

In practice, describes an AI solution that involves any or all of these:

1. Multiple LLM calls
    å¤šæ¬¡ LLM å‘¼å«
2. LLMs with ability to use Tools
    LLM èƒ½ä½¿ç”¨å·¥å…·ï¼ˆTools, e.g. Philips Hue)
3. An environment where LLMs interact
    å­˜åœ¨ LLM å½¼æ­¤äº’å‹•çš„ç’°å¢ƒ
4. A Planner to coordinate activities
    æœ‰ä¸€å€‹è¦åŠƒè€…ï¼ˆPlannerï¼‰ä¾†å”èª¿ä»»å‹™
5. Autonomy
    å…·å‚™è‡ªä¸»æ€§ï¼ˆAutonomyï¼‰
    - è‡ªä¸»å‹ï¼ˆæœ‰ autonomyï¼‰	å…·æœ‰ç›®æ¨™å°å‘çš„è¡Œç‚ºã€è‡ªå‹•æ±ºç­–èˆ‡**è¦åŠƒ**
---

### **Agentic Systems**
*Anthropic distinguishes two types:*

#### ğŸŸ¡ Workflows

> *are systems where LLMs and tools are orchestrated through predefined code paths*
ç³»çµ±ä¸­ï¼ŒLLM å’Œå·¥å…·çš„åŸ·è¡Œé †åºæ˜¯é€é**é å…ˆå®šç¾©å¥½çš„ç¨‹å¼è·¯å¾‘**æ‰€å”èª¿çš„ã€‚

#### ğŸ”´ Agents

> *are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks*
LLM èƒ½å¤ **å‹•æ…‹æŒ‡æ®è‡ªå·±çš„æµç¨‹èˆ‡å·¥å…·ä½¿ç”¨æ–¹å¼**ï¼Œä¸¦æŒçºŒæŒæ§ä»»å‹™å®Œæˆçš„æ–¹å¼ã€‚

---

ã€ŒWorkflowsã€èˆ‡ã€ŒAgentsã€åœ¨ Agentic ç³»çµ±ä¸­çš„**ä¸»æ§æ¬Šå·®ç•°**ï¼Œç°¡å–®ä¾†èªªï¼š

| é¡å‹        | ä¸»å°æ§åˆ¶   | æ±ºç­–æ–¹å¼      |
| --------- | ------ | --------- |
| Workflows | é–‹ç™¼è€…é è¨­  | ç…§æµç¨‹èµ°      |
| Agents    | LLM è‡ªä¸» | é‚Šèµ°é‚Šæƒ³ã€å³æ™‚é¸æ“‡ |

---

#### ğŸ§± **5 workflow design patterns**

**1. PROMPT CHAINING**
*Decompose into fixed sub-tasks*

```
IN â†’ LLM1 â†’ Gate (code, optional) â†’ LLM2 â†’ LLM3 â†’ OUT
```

---

#### ğŸ§  è§£é‡‹ï¼š

é€™æ˜¯ä¸€ç¨®å°‡è¤‡é›œä»»å‹™**æ‹†è§£æˆå¤šå€‹å›ºå®šæ­¥é©Ÿ**çš„ AI è¨­è¨ˆæ¨¡å¼ã€‚æ¯å€‹æ­¥é©Ÿç”±ä¸åŒçš„ LLM åŸ·è¡Œä¸€å€‹æ˜ç¢ºå­ä»»å‹™ï¼Œä¸¦**ä¸²æ¥æˆä¸€å€‹ç©©å®šæµç¨‹**ã€‚

#### ğŸ”„ èˆ‰ä¾‹æ‡‰ç”¨å ´æ™¯ï¼š

ä¾‹å¦‚é–‹ç™¼ä¸€å€‹è‡ªå‹•å…§å®¹ç”Ÿæˆå™¨ï¼š

1. LLM1 è§£æç”¨æˆ¶éœ€æ±‚
2. Gate åˆ¤æ–·ä»»å‹™é¡å‹ï¼ˆå¦‚æŠ€è¡“æ–‡ã€å»£å‘Šæ–‡ï¼‰
3. LLM2 æ’°å¯«åˆç¨¿
4. LLM3 ç·¨è¼¯èˆ‡æ ¼å¼åŒ–
5. OUT è¼¸å‡ºæœ€çµ‚æ–‡ç¨¿

---

**2. ROUTING**
*Direct an input into a specialized sub-task, ensuring separation of concerns*

```
IN â†’ LLM Router (with condition ONLY one LLM) â†’ (LLM1 / LLM2 / LLM3) â†’ OUT
```

---

#### ğŸ§  è§£é‡‹ï¼š

é€™ç¨®è¨­è¨ˆæ¨¡å¼çš„æ ¸å¿ƒæ˜¯**æ™ºèƒ½åˆ†æµ**ï¼Œæ ¹æ“šè¼¸å…¥çš„ä¸åŒé¡å‹ï¼Œè‡ªå‹•é¸æ“‡å°æ‡‰çš„ LLM æ¨¡å‹åŸ·è¡Œã€‚

#### ğŸ”„ èˆ‰ä¾‹æ‡‰ç”¨å ´æ™¯ï¼š

é–‹ç™¼å¤šåŠŸèƒ½å®¢æœä»£ç†äººï¼š

* LLM Router åˆ¤æ–·è¼¸å…¥ç‚º**æŠ€è¡“å•é¡Œ / è¡ŒéŠ·æŸ¥è©¢ / å¸³æˆ¶å•é¡Œ**
* å°æ‡‰åœ°åˆ†æ´¾çµ¦ LLM1ï¼ˆæŠ€è¡“æ”¯æ´ï¼‰ã€LLM2ï¼ˆæ¥­å‹™ï¼‰ã€LLM3ï¼ˆè²¡å‹™ï¼‰
* æœ€çµ‚çµ±ä¸€è¼¸å‡ºçµæœ

---

**3. PARALLELIZATION**
*Breaking down tasks and running multiple subtasks concurrently*

```
IN â†’ Coordinator (code) â†’ (LLM1 / LLM2 / LLM3 in parallel) â†’ Aggregator (code) â†’ OUT
```

---

#### ğŸ§  è§£é‡‹ï¼š

é€™ç¨®è¨­è¨ˆæ¨¡å¼å¼·èª¿æ•ˆç‡ï¼Œå°‡å¤§ä»»å‹™åˆ‡æˆ**å¯å¹³è¡ŒåŸ·è¡Œçš„å°ä»»å‹™**ï¼Œä¸¦è¡Œèª¿ç”¨å¤šå€‹ LLM åŒæ­¥è™•ç†ï¼Œæœ€å¾Œå†æ•´åˆçµæœã€‚

#### ğŸ”„ èˆ‰ä¾‹æ‡‰ç”¨å ´æ™¯ï¼š

åšä¸€ä»½å¸‚å ´å ±å‘Šï¼š

* å”èª¿å™¨å°‡ä»»å‹™æ‹†æˆä¸‰éƒ¨åˆ†ï¼šç”¢æ¥­åˆ†æã€ç«¶å“ç ”ç©¶ã€æ¶ˆè²»è€…èª¿æŸ¥
* ä¸‰å€‹ LLM åŒæ™‚è™•ç†ä¸‰å€‹å­é¡Œ
* èšåˆå™¨æ•´åˆä¸‰æ®µåˆ†æç‚ºä¸€ä»½å®Œæ•´å ±å‘Š

---

**4. ORCHESTRATOR-WORKER**
*Complex tasks are broken down dynamically and combined - refer to **Price is Right** in LLM Engineering Course*

```
IN â†’ Orchestrator (LLM) â†’ (LLM1 / LLM2 / LLM3) â†’ Synthesizer (LLM) â†’ OUT
```
---
### ğŸ§  è§£é‡‹ï¼š

æ­¤æ¨¡å¼ä¸­çš„ **Orchestratorï¼ˆæŒ‡æ®/èª¿åº¦è€…ï¼‰** ä¸åªæ˜¯è·¯ç”±ä»»å‹™ï¼Œè€Œæ˜¯**å‹•æ…‹æ‹†è§£è¤‡é›œä»»å‹™**ä¸¦åˆ†æ´¾çµ¦ä¸‹å±¬çš„ LLM ä»£ç†äººï¼Œå†ç”± **Synthesizer** çµ„åˆçµæœã€‚

#### ğŸ”„ èˆ‰ä¾‹æ‡‰ç”¨å ´æ™¯ï¼š

å»ºç«‹ç”¢å“å»ºè­°ç³»çµ±ï¼š

* Orchestrator æ ¹æ“šè¼¸å…¥éœ€æ±‚ï¼Œè‡ªå‹•æ‹†æˆåŠŸèƒ½ã€è¨­è¨ˆã€å¸‚å ´ç­‰å­ä»»å‹™
* å„å€‹ LLM å°ˆè²¬è™•ç†ä¸åŒé¢å‘
* Synthesizer å°‡å¤šé …è¼¸å‡ºæ•´åˆæˆå®Œæ•´ææ¡ˆå»ºè­°

---

**5. EVALUATOR-OPTIMIZER**
*LLM output is validated by another*

```
IN â†’ LLM Generator â†’ (Solution) â†’ LLM Evaluator  
â†’ Accept â†’ OUT  
    OR
â†’ Reject â†’ Feedback â†’ LLM Generator (loop)
```

---

### ğŸ§  è§£é‡‹ï¼š

é€™æ˜¯ä¸€ç¨®å…·å‚™ã€Œè‡ªæˆ‘å›é¥‹èˆ‡æ”¹é€²ã€èƒ½åŠ›çš„æ¶æ§‹ã€‚ç³»çµ±ç”±ä¸€å€‹ç”Ÿæˆæ¨¡å‹èˆ‡ä¸€å€‹è©•ä¼°æ¨¡å‹çµ„æˆï¼š

* ç”Ÿæˆå™¨è² è²¬ç”¢å‡ºåˆç¨¿æˆ–è§£æ³•
* è©•ä¼°å™¨è² è²¬é©—è­‰å“è³ªèˆ‡æ­£ç¢ºæ€§
* è‹¥ä¸ç¬¦åˆæ¨™æº–ï¼Œç³»çµ±æœƒå›é¥‹å»ºè­°ï¼Œä¸¦**é‡æ–°ç”Ÿæˆæ”¹é€²ç‰ˆ**

#### ğŸ”„ èˆ‰ä¾‹æ‡‰ç”¨å ´æ™¯ï¼š

è‡ªå‹•å¯«ä½œåŠ©æ‰‹ï¼š

* LLM ç”Ÿæˆæ–‡ç« æ®µè½
* ç¬¬äºŒå€‹ LLM æª¢æŸ¥æ˜¯å¦ç¬¦åˆèªæ°£ã€é¢¨æ ¼ã€é‚è¼¯
* è‹¥ä¸æ»¿æ„ï¼Œé€€å›ä¿®æ­£ç›´åˆ°é€šé

---

é€™ç¨®æ¨¡å¼ç‰¹åˆ¥é©åˆéœ€è¦**é«˜å“è³ªä¿è­‰**çš„ä»»å‹™ï¼Œå¦‚ç¨‹å¼ç¢¼ç”Ÿæˆã€æ³•å¾‹æ–‡æœ¬ã€é†«ç™‚å»ºè­°ç­‰ã€‚

---

#### Agents, by contrast, Agents are:

1. Open-ended **é–‹æ”¾å¼ä»»å‹™æµç¨‹**
   æ²’æœ‰æ˜ç¢ºçš„èµ·é»èˆ‡çµ‚é»ï¼Œèƒ½æ ¹æ“šéœ€æ±‚æŒçºŒé€²è¡Œ
2. **Feedback loops** **å›é¥‹è¿´åœˆ**
   æ ¹æ“šç’°å¢ƒå›é¥‹å‹•æ…‹èª¿æ•´è¡Œå‹•ç­–ç•¥èˆ‡æ±ºç­–
3. No fixed path **ç„¡å›ºå®šè·¯å¾‘**
   ä»»å‹™æµç¨‹éç·šæ€§ã€ä¸é è¨­é †åºï¼Œç”± LLM è‡ªä¸»æ±ºå®šå¦‚ä½•å®Œæˆç›®æ¨™

**æµç¨‹åœ–èªªæ˜**ï¼š

```
HUMAN â†’ LLM Call â†’ ENVIRONMENT <-> (Feedback)  
                          â†“  
                        STOP
```
* äººé¡æå‡ºä»»å‹™ â†’ LLM åšå‡ºæ±ºç­– â†’ èˆ‡å¤–éƒ¨ç’°å¢ƒäº’å‹•ï¼ˆå¦‚è¨­å‚™ã€ç¶²è·¯ã€è³‡æ–™åº«ï¼‰
* ç’°å¢ƒå›å‚³çµæœæˆ–åé¥‹ â†’ LLM æ ¹æ“šå›é¥‹å†èª¿æ•´ç­–ç•¥
* å¦‚æœ‰éœ€è¦ï¼Œå¯é‡è¤‡å¾ªç’°å¤šæ¬¡ï¼Œç›´åˆ°ä»£ç†äººæ±ºå®šåœæ­¢ï¼ˆSTOPï¼‰
---

ğŸ§  å°çµï¼š
| é¡å‹      | ç„¡è‡ªä¸»æ€§ LLMï¼ˆå‚³çµ±ï¼‰ | æœ‰è‡ªä¸»æ€§ **Agentic** LLM |
| ------- | ------------ | ---------------- |
| å›æ‡‰æ–¹å¼    | å›ç­”å–®ä¸€æŒ‡ä»¤       | å¤šè¼ªè¦åŠƒèˆ‡ç­–ç•¥åŸ·è¡Œ        |
| æµç¨‹æ§åˆ¶    | ç”±äººé¡é å…ˆå®šç¾©      | ç”± LLM è‡ªè¡Œè¦åŠƒèˆ‡èª¿æ•´    |
| å·¥å…·é¸æ“‡èˆ‡èª¿ç”¨ | è¢«å‹•ï¼ˆéœ€æŒ‡ç¤ºï¼‰      | ä¸»å‹•ä½¿ç”¨å·¥å…·/æŸ¥è©¢/é‡è©¦     |
| ä»»å‹™é€²é€€æ±ºç­–  | ç„¡æ±ºç­–èƒ½åŠ›        | å¯æ±ºå®šè¦ä¸è¦ç¹¼çºŒã€ä¿®æ­£é‚„æ˜¯çµ‚æ­¢  |

---

### ğŸ§± **Risks of Agent Frameworks**

ğŸ§­ **ğŸŸ§ Unpredictable path**
ğŸ”€ **ğŸŸ§ Unpredictable output**
ğŸ·ï¸ **ğŸŸ§ Unpredictable costs**

ğŸ“¹ **ğŸ”µ Monitor**
ğŸš† **ğŸ”µ *"Guardrails ensure your agents behave safely, consistently, and within your intended boundaries"***

* ğŸŸ§ æ©˜è‰²ï¼š**é¢¨éšªé …ç›®**ï¼ˆä¸å¯é æ¸¬æ€§ï¼‰
* ğŸ”µ è—è‰²ï¼š**æ§åˆ¶èˆ‡é˜²è­·æªæ–½**ï¼ˆç›£æ§èˆ‡é˜²è­·æ¬„ï¼‰

---

### Guardrails 
#### ğŸ”’ ä»€éº¼æ˜¯ Guardrailsï¼Ÿ

åœ¨ Agentic AI ä¸­ï¼Œ**Guardrailsï¼ˆé˜²è­·æ¬„ï¼‰**æ˜¯ä¸€ç¨®é™åˆ¶èˆ‡ä¿è­·æ©Ÿåˆ¶ï¼Œç›®çš„æ˜¯è®“ LLM æˆ–ä»£ç†äººç³»çµ±åœ¨**å®‰å…¨ã€å¯æ§çš„ç¯„åœå…§é‹ä½œ**ï¼Œé˜²æ­¢å®ƒå€‘åé›¢é æœŸè¡Œç‚ºã€‚

å®ƒå°±åƒæ˜¯è‡ªå‹•é§•é§›æ±½è»Šæ—é‚Šçš„è­·æ¬„â€”â€”ä¸æœƒé˜»æ­¢è»Šå­å‰é€²ï¼Œä½†æœƒé˜²æ­¢å®ƒè¡å‡ºé“è·¯ã€‚

---

### âœ… Guardrails çš„åŠŸèƒ½ï¼š

1. âœ… **é™åˆ¶è¼¸å…¥/è¼¸å‡ºå…§å®¹æ ¼å¼**
2. âœ… **é™åˆ¶å·¥å…·/API çš„ä½¿ç”¨ç¯„åœ**
3. âœ… **é™åˆ¶æ“ä½œæ™‚é–“æˆ–å¾ªç’°æ¬¡æ•¸**
4. âœ… **å¼·åˆ¶åŸ·è¡Œå®‰å…¨ã€å€«ç†ã€åˆè¦è¦å‰‡**

---

#### ğŸ“Œ å¯¦éš›ç¯„ä¾‹èªªæ˜

---

#### ğŸ§  ç¯„ä¾‹ 1ï¼šé˜²æ­¢ä¸ç•¶è¼¸å‡º

#### â“ä»»å‹™ï¼š

> ä½¿ç”¨è€…è¼¸å…¥ï¼šã€Œè«‹å¯«ä¸€æ®µæœ‰çˆ­è­°çš„æ”¿æ²»è©•è«–ã€

#### ğŸ›¡ï¸ Guardrailï¼š

è¨­å®š LLM ä¸å¾—ç”Ÿæˆï¼š

* æ”¿æ²»ç«‹å ´åé —å…§å®¹
* èª¹è¬—/ä»‡æ¨è¨€è«–
* é•å OpenAI ä½¿ç”¨æ”¿ç­–çš„è©±èª

ğŸ”§ å¯¦ä½œæ–¹å¼ï¼š

* ä½¿ç”¨ prompt injection æ””æˆªå™¨æˆ–å…§å®¹éæ¿¾å™¨
* ä½¿ç”¨ LLM è©•ä¼°å™¨æª¢æŸ¥è¼¸å‡ºå‰è‡ªå‹•å¯©æ ¸

---

#### ğŸ§  ç¯„ä¾‹ 2ï¼šé™åˆ¶ API ä½¿ç”¨æ¬¡æ•¸

#### â“ä»»å‹™ï¼š

> è®“ä»£ç†äººä½¿ç”¨ Bing æœå°‹æœ€æ–°é†«ç™‚è³‡è¨Š

#### ğŸ›¡ï¸ Guardrailï¼š

é™åˆ¶ï¼š

* æœ€å¤šå¯æŸ¥è©¢ 5 æ¬¡
* ç¦æ­¢æŸ¥è©¢ç‰¹å®šé—œéµå­—ï¼ˆå¦‚ã€Œbuy drugsã€ï¼‰

ğŸ”§ å¯¦ä½œæ–¹å¼ï¼š

* è¨­å®š tools åŸ·è¡Œé™åˆ¶
* åŠ å…¥ middleware ç›£æ§å‘¼å«è¡Œç‚º

---

#### ğŸ§  ç¯„ä¾‹ 3ï¼šæ§åˆ¶æµç¨‹æ·±åº¦èˆ‡æˆæœ¬

#### â“ä»»å‹™ï¼š

> è®“ Agent è‡ªä¸»è¦åŠƒä¸€å€‹å•†æ¥­ç­–ç•¥ï¼ŒåŒ…å«ç«¶çˆ­åˆ†æèˆ‡è²¡å‹™æ¨¡å‹

#### ğŸ›¡ï¸ Guardrailï¼š

* æœ€å¤šåªèƒ½å‘¼å« 3 å±¤ LLM ä»»å‹™éˆ
* æ¯æ¬¡è¿´åœˆä¸å¾—è¶…é 60 ç§’
* é ç®—é™åˆ¶ï¼ˆä¾‹å¦‚ token ç”¨é‡ä¸è¶…é 100,000ï¼‰

ğŸ”§ å¯¦ä½œæ–¹å¼ï¼š

* è¨­å®š task depth é™åˆ¶
* ç”¨ token è¨ˆæ•¸å™¨æˆ–è€—æ™‚ç›£æ§å™¨

---

#### âœ… å·¥å…·èˆ‡æ¡†æ¶æ”¯æ´ Guardrailsï¼š

| å·¥å…·/æ¡†æ¶                 | Guardrail åŠŸèƒ½                                       |
| --------------------- | -------------------------------------------------- |
| **OpenAI Agents SDK** | å…§å»ºè¦å‰‡ç³»çµ±å¯è¨­å®šè¡Œç‚ºé™åˆ¶ã€å…§å®¹ç¯©é¸                                 |
| **GuardrailsAI**      | è‡ªè¨‚è¼¸å…¥/è¼¸å‡ºæ ¼å¼ã€é©—è­‰è¦å‰‡ã€éŒ¯èª¤å›é¥‹                                |
| **LangChain**         | ä½¿ç”¨ callback + tool call constraints ä¾†å¯¦ä½œ guardrails |
| **Rebuff / ReAct**    | å¢åŠ ä¸­é–“æ±ºç­–æ­¥é©Ÿä»¥æ§åˆ¶éŒ¯èª¤å·¥å…·èª¿ç”¨æˆ–éåº¦å›åœˆ                             |

---

### ğŸ§¾ å°çµ

| å°è±¡     | Guardrail æ•ˆæœ      |
| ------ | ----------------- |
| LLM å›æ‡‰ | é¿å…ç”Ÿæˆæ•æ„Ÿ/éŒ¯èª¤/ä¸åˆè¦å…§å®¹   |
| å·¥å…·ä½¿ç”¨   | æ§åˆ¶èª¿ç”¨é »ç‡ã€å…§å®¹èˆ‡é¡å‹      |
| ä»»å‹™æµç¨‹   | é¿å…ç„¡é™è¿´åœˆã€æˆæœ¬çˆ†è¡¨ã€ä¸æ”¶æ–‚ä»»å‹™ |

---

## Week 1 Day 3

---
### **Calling multiple LLMs**

- We will be calling **Paid APIs** and **open-source** models in the **cloud** and **locally** throughout this course.

- You have complete flexibility to pick which you use,
and can **spend \$0**.

- More on **selecting, applying** and **deploying** LLMs with my **LLM Engineering** course.

---
### **The cast of characters**

- **OpenAI:** gpt-4o-mini (also gpt-4o, o1, o3-mini)
- **Anthropic:** Claude-3-7-Sonnet
- **Google:** Gemini-2.0-flash
- **DeepSeek AI:** DeepSeek V3, DeepSeek R1
- **Groq:** open-source LLMs including Llama3.3
- **Ollama:** local open-source LLMs including Llama3.2

**The Vellum leaderboard** gives a comparison of costs and performance ([https://www.vellum.ai/llm-leaderboard](https://www.vellum.ai/llm-leaderboard))

---

A breakdown of the **differences between the "cast of characters"** listed in your image â€” major LLM providers â€” focusing on their **origin, specialization, performance, openness, and hosting options**:

---

### ğŸ§¾ **Overview Table:**

| Provider        | Model(s)             | Type                | Hosting                    | Notable Features                                         |
| --------------- | -------------------- | ------------------- | -------------------------- | -------------------------------------------------------- |
| **OpenAI**      | gpt-4o, gpt-4o-mini  | Proprietary         | Cloud (OpenAI, Azure)      | Multimodal, strong reasoning, long-context dialogue      |
| **Anthropic**   | Claude-3-7-Sonnet    | Proprietary         | Cloud (Claude.ai, Bedrock) | Long context, safe alignment, balanced tone              |
| **Google**      | Gemini-2.0-flash     | Proprietary         | Cloud (Vertex AI)          | Fast responses, integrates with Google ecosystem         |
| **DeepSeek AI** | DeepSeek V3, R1      | Commercial/Research | Self-host or Cloud         | Strong multilingual reasoning, trained on web-scale data |
| **Groq**        | Llama3.3 on Groq LPU | Open-source runtime | Cloud (GroqCloud)          | Ultra-fast inference on custom LPU hardware              |
| **Ollama**      | Llama3.2             | Open-source         | Local (Desktop/Edge)       | Easy local setup, lightweight, offline-capable           |

---

### ğŸ” **Detailed Differences by Category**

### ğŸ§  **1. Intelligence & Reasoning Power**

* **Strongest models**: OpenAI GPT-4o, Anthropic Claude 3, DeepSeek V3
* **Fastest models**: Google Gemini Flash, Groq (LPU-powered)

### ğŸ§© **2. Openness**

* **Open-source**: DeepSeek, Groq (runs open models), Ollama
* **Closed-source**: OpenAI, Anthropic, Google

### ğŸ–¥ï¸ **3. Hosting/Deployment**

* **Cloud-only**: OpenAI, Claude, Gemini
* **Local/Edge-ready**: Ollama, DeepSeek
* **Hybrid (cloud API + self-host)**: Groq, DeepSeek

### ğŸ’° **4. Cost**

* **Free options**: Ollama (run models locally, no API cost)
* **Paid APIs**: OpenAI, Anthropic, Google
* **Groq**: Very low-cost due to their own LPU hardware

---

### âœ… **When to Use What**

| Need                              | Recommendation          |
| --------------------------------- | ----------------------- |
| Best reasoning/completion         | GPT-4o, Claude 3        |
| Cost-effective local use          | Ollama with Llama 3.2   |
| Fastest inference for production  | Groq + Llama3.3         |
| Open research / customization     | DeepSeek V3 or Mistral  |
| Cloud-native business integration | Google Gemini or OpenAI |

---

ğŸ¤” Use LPU or GPU?
| Scenario                            | Best Fit                 |
| ----------------------------------- | ------------------------ |
| Training your own model             | **GPU**                  |
| Hosting general AI workloads        | **GPU**                  |
| Serving ultra-fast chatbot response | **LPU** (e.g. GroqCloud) |
| Local prototyping                   | **GPU/CPU** (or Ollama)  |

**å®¢æœ** Chatbotï¼ˆCustomer Service AIï¼‰é€™é¡**é«˜ä½µç™¼ã€ä½å»¶é²**çš„æ‡‰ç”¨å ´æ™¯ä¾†èªªï¼Œä½¿ç”¨ **LPU**ï¼ˆLanguage Processing Unitï¼‰ï¼Œé€šå¸¸æ¯” GPU æ›´åˆé©

---

1_foundations/2_lab2.ipynb

## Week 1 Day 4

### Hereâ€™s the image text represented with color-coded labels and layout (bottom-up):

---

**ğŸŸ¦ Bottom Row (Blue):**

* **No framework**
* **MCP**

**ğŸŸ© Middle Row (Light Green):**

* **OpenAI Agents SDK**
* **Crew AI**

**ğŸŸ« Top Row (Brown):**

* **LangGraph**
* **AutoGen**

### ğŸ–ï¸ Color Legend

* **ğŸŸ¦ Blue**: Lower-level or standard options
* **ğŸŸ© Light Green**: Emerging agentic AI SDKs (notable middle ground)
* **ğŸŸ« Brown**: Advanced, graphâ€‘ or generationâ€‘oriented agentic frameworks

---

### What is MCP?
**MCP** æ˜¯ **Model Context Protocol** çš„ç¸®å¯«ï¼Œä¸€ç¨®ç”± **Anthropic** åœ¨ **2024 å¹´ 11 æœˆ**æå‡ºçš„**é–‹æ”¾æ¨™æº–**ï¼Œç›®çš„æ˜¯æˆç‚ºè®“å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰èˆ‡å¤–éƒ¨å·¥å…·ã€è³‡æ–™æºå®‰å…¨äº¤äº’çš„ã€Œ**çµ±ä¸€é€šè¨Šè¦ç¯„**ã€ã€‚

---

### ğŸ“˜ MCP ä¸»è¦åŠŸèƒ½èˆ‡ç‰¹è‰²

### ğŸ§© 1. çµ±ä¸€ä»‹é¢ï¼ˆâ€œUSBâ€‘C for AIâ€ï¼‰

* å°‡ LLM èˆ‡æª”æ¡ˆç³»çµ±ã€è³‡æ–™åº«ã€APIã€ç¬¬ä¸‰æ–¹å·¥å…·ï¼ˆå¦‚ GitHubã€Slackã€PostgreSQL ç­‰ï¼‰é€éæ¨™æº–åŒ–å”å®šé€£æ¥ï¼Œå…å»ç‚ºæ¯å€‹ä¾†æºåˆ†åˆ¥å¯«æ•´åˆç¨‹å¼ã€‚
* é¡ä¼¼**è¬ç”¨æ¥é ­**ï¼Œé€£æ¥ä¸åŒè¨­å‚™èˆ‡è³‡æ–™æºã€‚

### ğŸ”„ 2. é›™å‘å®‰å…¨äº’å‹•

* ä½¿ç”¨ **JSONâ€‘RPC 2.0** é€šè¨Šå”å®šï¼Œå®šç¾©æ¸…æ¥šçš„è«‹æ±‚èˆ‡å›æ‡‰æ ¼å¼ï¼Œæ”¯æ´é›™å‘äº’å‹•ï¼Œä¹Ÿèƒ½æ”œå¸¶ metadataï¼ˆå¦‚æ¨¡å‹ç‰ˆæœ¬ã€æ¬Šé™è³‡è¨Šï¼‰ã€‚
* æ”¯æ´ **tool permission negotiation**ï¼Œç¢ºä¿ä»£ç†ç¨‹å¼åªèƒ½åŸ·è¡Œè¢«æˆæ¬Šçš„æ“ä½œã€‚

### âš™ï¸ 3. é–‹æºèˆ‡è·¨å¹³å°ç”Ÿæ…‹

* **Anthropic** æä¾› **MCP ä¼ºæœå™¨**èˆ‡**å®¢æˆ¶ç«¯ SDK**ï¼ˆPythonã€TypeScriptã€Javaã€C# ç­‰ï¼‰ã€‚
* **OpenAI**ã€**Google DeepMind**ã€**Microsoft** ç­‰å‡å·²æ¡ç”¨ MCPï¼Œå”åŒæ‰“é€ é¡ä¼¼ **HTTP çš„ AI Agent å”å®š**ã€‚

---

### ğŸ—£ï¸ MCP çš„ä½¿ç”¨å ´æ™¯

* **æ¡Œé¢åŠ©æ‰‹**ï¼šå¦‚ Claude Desktop ä½¿ç”¨æœ¬åœ° MCP server è®€å–æ–‡ä»¶ã€æ“ä½œç³»çµ±æŒ‡ä»¤ã€‚
* **ä¼æ¥­æ‡‰ç”¨**ï¼šå¦‚ Blockã€Replitã€Sourcegraph ä½¿ç”¨ MCP é€£æ¥å…§éƒ¨è³‡æ–™åº«å’Œæ¥­å‹™å·¥å…·ã€‚
* **å·¥å…·ä¸²æ¥å¤š Agent æµç¨‹**ï¼šMCP æ”¯æ´ agent åˆ° agent æˆ– agent åˆ° service çš„å”èª¿èˆ‡è³‡æ–™æµè½‰ã€‚

---

### âœ¨ MCP çš„å„ªé»

* **å¯æ“´å……æ€§**ï¼šç„¡éœ€ç‚ºæ¯ç¨®å·¥å…·é‡å¯«æ¥å£ï¼Œåªéœ€é€é **MCP server é€£æ¥ä¸€æ¬¡**ã€‚
* **è·¨æ¨¡å‹ã€è·¨å¹³å°é€šç”¨**ï¼šæ”¯æ´å¤šç¨® LLM æä¾›çš„ **Agent SDK**ï¼Œä¾‹å¦‚ Claudeã€OpenAI Agents SDK ç­‰ã€‚
* **å®‰å…¨èˆ‡å¯©è¨ˆ**ï¼šå¯ç®¡ç† tool æ¬Šé™ï¼Œæä¾› metadataã€æ—¥èªŒèˆ‡å¯è¿½æº¯æ€§ã€‚

---

### âœ… å°çµ

MCP æ˜¯ä¸€ç¨®çµ±ä¸€ã€é–‹æºã€å®‰å…¨ä¸”è·¨æ¨¡çµ„é€šç”¨çš„ä»‹é¢å”å®šï¼Œä½¿å¾— **AI Agent** èƒ½å¤ åƒä½¿ç”¨ **USBâ€‘C** çš„æ–¹å¼ï¼Œ**ä¸€æ¬¡æ€§é€£æ¥å¤šç¨®å·¥å…·èˆ‡è³‡æ–™æº**ï¼Œä¸¦åŸ·è¡Œé›™å‘äº¤äº’ã€‚å·²è¢«å¤šå®¶é ˜å°è€…æ¡ç”¨ï¼Œæ¨å‹•äº† **AI Agent çš„ç”Ÿæ…‹å»ºè¨­**ã€‚

---

### A practical example of how **MCP** (Model Context Protocol) works in real-world use:

### ğŸ§© Example: Adding a Postgres MCP Server with Claude CLI

Using the `claude` CLI, you can register an MCP server that lets Claude communicate with a PostgreSQL database:

```bash
# Register a local Postgres MCP server
claude mcp add postgres-server /path/to/postgres-mcp-server \
  --connection-string "postgresql://user:pass@localhost:5432/mydb"
```

Once registered, you can query your database directly in Claude:

```
> describe the schema of our users table
> what are the most recent orders in the system?
```

This setup uses **MCP JSONâ€‘RPC messages** under the hood to:

1. Discover schema (`resources`)
2. Execute queries (`tools`)
3. Return structured JSON results to Claude for interpretation and response ([docs.anthropic.com][1]).

---

### ğŸ”§ Another Example: C# MCP Server Setup

With the **C# MCP SDK**, you can build a simple MCP server like this:

**Program.cs:**

```csharp
using ModelContextProtocol.Server;
using Microsoft.Extensions.Hosting;

var builder = Host.CreateDefaultBuilder(args)
  .ConfigureServices(services => {
    services.AddMcpServer()
      .AddFileSystemTool()    // Expose tools like list/read/write
      .AddPostgresProvider(); // Expose queries to a PostgreSQL DB
  });
await builder.RunConsoleAsync();
```

This spins up a server exposing **file system** and **Postgres** tools via MCP for any clientâ€”including Claude or OpenAIâ€”to connect securely ([devblogs.microsoft.com][2]).

---

### âš™ï¸ Workflow Summary

1. **Server** defines available tools/resources (DB queries, file actions).
2. **Client** (AI agent) discovers them via MCP metadata.
3. **Client** invokes tools (e.g., `mcp_tool_call`) to fetch or manipulate data.
4. **Server** responds with structured JSON and metadata back to the LLM.

---

### âœ… Why this matters

* **Modular**: Add new data sources by plugging into MCP.
* **Standardized**: No need to create custom APIs for each tool.
* **Secure**: Clients only access registered tools with defined permissions.
* **Multi-language**: SDKs in Python, C#, TS, Java, etc., allow broad adoption.

---

### ğŸ  åœ¨å“ªè£¡éƒ¨ç½² MCP Server æ¯”è¼ƒåˆé©ï¼Ÿ

#### æœ¬åœ° (Local Machine)

* **åƒ…é™æ–¼ä½ è‡ªå·±çš„ä¸»æ©Ÿ**ï¼Œä¾‹å¦‚ Claude Desktop ä½¿ç”¨çš„ MCP å°±æ˜¯æœ¬åœ°é€é `stdio` é€šè¨Šã€‚
* å¥½è™•æ˜¯ï¼šå®Œå…¨ä¸å°å¤–å…¬é–‹ï¼Œå®‰å…¨æ€§é«˜ã€æ¶è¨­ç°¡å–®ï¼Œéå¸¸é©åˆå€‹äººæˆ–å…§éƒ¨é–‹ç™¼æ¸¬è©¦ç’°å¢ƒã€‚

#### ç§æœ‰é›² (Private Cloud/VPC)

* MCP Server å¯éƒ¨ç½²åœ¨ä½ è‡ªå·±çš„ç§æœ‰é›²æˆ–å…¬å¸ VPC ä¸­ï¼ˆå¦‚ Kubernetesã€AWS VPCã€GCP Private Cloudï¼‰ã€‚
* å¯ä»¥ä½¿ç”¨ HTTP(S) æˆ– SSE é€šè¨Šï¼Œå¹¶è¨­ç½®ä¼æ¥­æ¨™æº–çš„å®‰å…¨æ©Ÿåˆ¶ï¼Œå¦‚ OAuth/LB/WAF/VPN/ACL ç­‰ã€‚
* é©åˆä¼æ¥­å ´æ™¯ï¼Œå¯å¾å…§éƒ¨å·¥å…·æˆ–é›²ç«¯ Agent å®‰å…¨å‘¼å«æœå‹™ï¼Œç„¡éœ€èµ°å…¬å…±äº’è¯ç¶²ã€‚

---

### âœ… ç¸½çµæ¯”è¼ƒ

| éƒ¨ç½²ä½ç½®           | é€šè¨Šæ–¹å¼                 | å®‰å…¨æ€§               | ä½¿ç”¨å ´æ™¯            |
| -------------- | -------------------- | ----------------- | --------------- |
| **æœ¬åœ° (Local)** | stdio (stdin/stdout) | â­â­â­â­ éå¸¸é«˜ï¼ˆåƒ…æœ¬åœ°ï¼‰     | å€‹äººæ¡Œé¢ã€é–‹ç™¼æ¸¬è©¦ç’°å¢ƒ     |
| **ç§æœ‰é›²/VPC**    | HTTP(S) / SSE        | â­â­â­â­ é«˜ï¼ˆç§æœ‰ç¶²è·¯ + èªè­‰ï¼‰ | ä¼æ¥­å…§éƒ¨ã€å¤š Agent çµåˆ |
| **å…¬å…±é›²æˆ– Web**   | HTTP ç•¶ç„¶å¯ç”¨ï¼Œä½†éœ€**è¬¹æ…æš´éœ²** | â­ å–æ±ºæ–¼å®‰å…¨è¨­ç½®         | éœ€å¤§é‡å¤–éƒ¨è…³æœ¬æˆ–å®¢æˆ¶ç«¯æ™‚    |

---

### ğŸ” ç‚ºä»€éº¼é¸æ“‡é€™æ¨£ï¼Ÿ

* **è³‡æ–™èˆ‡ schema ä¸æœƒå¤–æ´©**ï¼šåªè¦ MCP Server æœªå°ç¶²éš›ç¶²è·¯é–‹æ”¾ï¼Œ**schema ä¸æœƒæš´éœ²**ã€‚
* **ä½¿ç”¨è®€/å¯«æ¬Šé™æ§åˆ¶**ï¼šå¯è¨­ã€Œæœ€å°æ¬Šé™åŸå‰‡ã€ï¼Œä¾‹å¦‚åƒ… Read-Only å¸³è™Ÿã€‚
* **å¯è¨­å®š tool-level ACL**ï¼šé™åˆ¶å“ªäº›å‘½ä»¤ï¼å·¥å…·å¯ä»¥è¢«å¤–éƒ¨ client å‘¼å«ã€‚
* **å®‰å…¨æ€§é«˜**ï¼šMCP Server æ¶è¨­åœ¨æœ¬åœ°æˆ–ç§æœ‰é›²ç’°å¢ƒï¼Œèƒ½ç¢ºä¿è³‡æ–™å®‰å…¨èˆ‡æ§åˆ¶ç¯„åœã€‚
* **å¯æ§æ€§å¼·**ï¼šä½ å¯ä»¥å®Œå…¨æ§åˆ¶ MCP Server çš„é…ç½®èˆ‡è¡Œç‚ºï¼Œç„¡éœ€ä¾è³´ç¬¬ä¸‰æ–¹æœå‹™ã€‚

ã€ŒMCP Server æ¶è¨­åœ¨ Local æˆ–ä½ çš„ Private Cloud ç’°å¢ƒå°±å¯ä»¥ç¢ºä¿æŒæœ‰å®‰å…¨ä¸”å¯æ§çš„ä½¿ç”¨ç¯„åœã€‚ã€ä½¿ç”¨ Docker Compose æˆ– Kubernetesï¼‰ä¸¦åŠ å…¥å®‰å…¨é…ç½®æŒ‡å¼•ã€‚

---

### **Resources**
- We can provide an LLM with resources to **improve its expertise**
    æˆ‘å€‘å¯ä»¥ç‚º LLM æä¾›è³‡æºï¼Œä»¥æå‡å…¶å°ˆæ¥­èƒ½åŠ›
- Basically, this just means **shoving data relevant to the question into the prompt**
    åŸºæœ¬ä¸Šï¼Œå°±æ˜¯æŠŠèˆ‡å•é¡Œç›¸é—œçš„è³‡æ–™å¡å…¥ prompt ä¸­
- There are techniques like **RAG** to get really smart at picking **relevant content**
    æœ‰ä¸€äº›æŠ€å·§â€”ä¾‹å¦‚ **RAGï¼ˆRetrieval Augmented Generationï¼‰**â€”å¯ä»¥æ›´ç²¾æº–åœ°æŒ‘é¸ç›¸é—œå…§å®¹

---

### ğŸ’¡ é—œéµæ¦‚å¿µèªªæ˜

1. **Shoving data into the prompt**
   æŒ‡çš„æ˜¯å°‡ç›¸é—œçš„è³‡æ–™é›†æˆ–ç‰‡æ®µï¼ˆå¦‚æ–‡ç« ã€ç”¢å“è³‡è¨Šã€æ•¸æ“šåº«å…§å®¹ï¼‰åŠ å…¥åˆ° prompt çš„ context ä¸­ï¼Œè®“ LLM å›ç­”æ™‚å¯ä»¥æ ¹æ“šé€™äº›ã€Œåœ¨ situã€çš„è³‡è¨Šé€²è¡Œæ¨ç†ã€‚

2. **RAGï¼ˆæª¢ç´¢å¢å¼·ç”Ÿæˆï¼‰**
   æ˜¯ä¸€ç¨®å¸¸è¦‹åšæ³•ï¼Œåˆ†ç‚ºä¸‰æ­¥ï¼šç´¢å¼• â†’ æª¢ç´¢ â†’ ç”Ÿæˆã€‚

   * å…ˆå°‡è³‡æ–™åˆ‡ç‰‡ä¸¦è½‰ç‚ºå‘é‡å„²å­˜ï¼ˆå¦‚å‘é‡è³‡æ–™åº«ï¼‰
   * æ ¹æ“šä½¿ç”¨è€…æå•æª¢ç´¢æœ€ç›¸é—œçš„ç‰‡æ®µ
   * æŠŠé€™äº›ç‰‡æ®µè£œå……åˆ° prompt å‰ï¼Œå†è«‹ LLM å›ç­”
     é€™èƒ½æœ‰æ•ˆæå‡å›æ‡‰çš„**æº–ç¢ºåº¦ã€äº‹å¯¦æ€§èˆ‡æ™‚æ•ˆæ€§** ã€‚

3. **ç‚ºä½•é€™éº¼åšï¼Ÿ**

   * ä¸éœ€é‡è¨“æ¨¡å‹ï¼Œåªé  prompt å³å¯æ“´å……çŸ¥è­˜
   * é™ä½å¹»è¦ºç™¼ç”Ÿç‡ï¼ˆhallucinationï¼‰ï¼Œå› ç‚ºæ¨¡å‹æœ‰å¯¦è­‰è³‡æ–™ä½œåŸºç¤ 
   * å¯å‹•æ…‹æ›´æ–°è³‡æ–™ï¼Œä¿æŒè³‡è¨Šæ–°é®®ï¼Œä»ä¸ç”¨é‡æ–°è¨“ç·´

---

### ğŸ§¾ å°çµ

* **"Shoving data into prompt"** æ˜¯ RAG çš„æ ¸å¿ƒæ€è·¯ï¼šå…ˆæª¢ç´¢è³‡æ–™ï¼Œå†å¡å…¥ prompt ä¸­
* **RAG pipeline** ä¸‰æ­¥é©Ÿï¼š**å‘é‡åŒ– â†’ æª¢ç´¢ â†’ è£œ prompt â†’ ç”Ÿæˆ** 
* å¥½è™•æ˜¯ï¼š**æº–ç¢ºåº¦é«˜ã€æ›´æ–°éˆæ´»ã€ä½æˆæœ¬éƒ¨ç½²**

---

### Tools and Techniques
â€œToolsâ€ ä¸º LLM å¸¦æ¥ **è‡ªä¸»æ“ä½œèƒ½åŠ›ï¼ˆautonomyï¼‰**ï¼Œæ„æ€æ˜¯è®©è¯­è¨€æ¨¡å‹ä¸ä»…èƒ½â€œæ€è€ƒâ€ï¼Œè¿˜å¯ä»¥**ä¸»åŠ¨æ‰§è¡Œå®é™…åŠ¨ä½œ**ï¼Œå¦‚ï¼š

* ğŸ’¾ **æŸ¥è¯¢æ•°æ®åº“ï¼ˆquery a databaseï¼‰**
* ğŸ¤– **å‘¼å«å…¶ä»– LLMï¼ˆmessage other LLMsï¼‰**
* ğŸŒ **Philips Hue** é–‹ç‡ˆ é—œç‡ˆ è®Šæ›é¡è‰²ç­‰

è½èµ·ä¾†å¯èƒ½æœ‰é»å¯æ€•â”€â”€â€œOpenAI èƒ½é€²å…¥æˆ‘çš„é›»è…¦ï¼Ÿâ€â”€â”€ä½†**çœŸç›¸å…¶å¯¦å¾ˆå¹³å‡¡**ï¼š
é€™äº› â€œtoolsâ€ å°±åƒè¢«**æˆæ¬Š**çš„**å‡½å¼**æˆ–**å¾®æœå‹™**ï¼Œåªæ˜¯è®“ LLM å¯ä»¥é€éã€Œç™¼å‡ºæŒ‡ä»¤ â†’ å¾…å‘½åŸ·è¡Œä¸¦å›å‚³çµæœã€çš„æ–¹å¼èˆ‡å¤–éƒ¨ç³»çµ±äº’å‹•ï¼Œè€ŒéçœŸæ­£å…¥ä¾µä½ çš„è³‡æ–™ ã€‚

---

### âœ… ç¤ºä¾‹ï¼šLLM çµåˆ Tools çš„å¯¦éš›å ´æ™¯

### ğŸ”§ ç¯„ä¾‹ 1ï¼šè‡ªç„¶èªè¨€æŸ¥è³‡æ–™ï¼ˆText-to-SQL Agentï¼‰

* **ä½¿ç”¨è€…èªª**ï¼šã€Œå‘Šè¨´æˆ‘ä¸Šå€‹æœˆçš„ç¸½éŠ·å”®é¡ï¼Ÿã€
* **LLM åˆ¤æ–·**ï¼šéœ€è¦ç”¨ SQL æŸ¥è³‡æ–™
* **å‘¼å« tool**ï¼š`generate_sql_query(user_input)`
* **åŸ·è¡Œ tool**ï¼šé€è‡³è³‡æ–™åº«
* **å–å¾—çµæœ**ï¼Œè¿”å›çµ¦ LLM
* **LLM çµ„åˆç­”è¦†**ï¼šã€Œä¸Šå€‹æœˆç¸½éŠ·å”®é¡æ˜¯ \$50,000ã€‚ã€
  é€™å€‹éç¨‹ä¸­ï¼ŒLLM ä¸»å‹•åˆ†æéœ€æ±‚ã€é¸ç”¨ toolã€è™•ç†çµæœï¼Œå±•ç¤ºè‡ªä¸»æ“ä½œã€‚

---

### ğŸ”§ ç¯„ä¾‹ 2ï¼šå¤š LLM å”ä½œ

* LLM å¯ä»¥å‘¼å«å…¶ä»– LLMï¼Œä¾‹å¦‚è®“ Claude **å¯©æŸ¥** GPT ç”¢å‡ºçš„çµæœ
* ç›¸äº’å°è©±ã€æ ¡å°ï¼Œå½¢æˆä¸€å€‹å¤šäººå”åŒä»£ç†ç³»çµ±
  é€™å°±æ˜¯ã€Œmessage other LLMsã€ï¼Œæå‡å“è³ªèˆ‡å®‰å…¨æ€§ã€‚

---

### ğŸ¯ ç‚ºä»€éº¼ Tools å¢åŠ äº†è‡ªä¸»æ€§

* **ä¸»å‹•æ±ºç­–**ï¼šLLM ä¸å†åªæ˜¯å–®ä¸€è¼¸å‡ºï¼Œè€Œæ˜¯åœ¨**å¯¦éš›æµç¨‹æ§åˆ¶ä¸­**åšå‡ºèª¿ç”¨é¸æ“‡
* **äº’è¯å¤–éƒ¨ç³»çµ±**ï¼šå¦‚è³‡æ–™åº«ã€APIã€Webã€å·¥å…·ï¼Œæ§‹æˆé–‰ç’°å›é¥‹æµç¨‹
* **æ›´å¤§å•é¡Œè™•ç†èƒ½åŠ›**ï¼šå¯é€²è¡Œå‹•æ…‹æŸ¥é©—ã€å›é¥‹ã€è‡ªæˆ‘ä¿®æ­£ï¼Œé è¶…å‚³çµ±â€œåªå›æ‡‰ promptâ€çš„æ–¹å¼

---

### âš ï¸ å·¥å…·ä½¿ç”¨çš„é¢¨éšª & é˜²è­·æªæ–½

* ğŸ§  **æ½›åœ¨æ¿«ç”¨**ï¼šå…·å‚™å¤§è¦æ¨¡ API å‘¼å«è³‡æºå¯é€ æˆè³‡å®‰é¢¨éšªæˆ–è³‡æ–™æ´©æ¼ 
* ğŸ›¡ï¸ **é˜²è­·å°ç­–**ï¼šéœ€è¦è¨­å®š guardrailsï¼ˆå¦‚ API å‘¼å«é™åˆ¶ã€æ¬Šé™æ§ç®¡ã€è¼¸å…¥é©—è­‰ï¼‰ä¾†ä¿éšœå®‰å…¨ã€‚

---

### ğŸ§© å°çµ

â€œToolsâ€ çµ¦ LLM å¸¶ä¾†äº†çœŸæ­£çš„ **è¡Œå‹•èƒ½åŠ›**ï¼Œè®“å®ƒå€‘å¯ä»¥è‡ªè¡Œï¼š

1. **æ±ºå®šä½•æ™‚åšä»€éº¼**
2. **å‘¼å«å“ªäº›å·¥å…·æˆ–å…¶ä»– LLM**
3. **è§£æå›å‚³è³‡æ–™ä¸¦åšæ±ºç­–**

é€™ä¸åªæ˜¯å‡è£å¼·å¤§ï¼Œè€Œæ˜¯å¯¦éš›ä¸Šè®“ LLM æˆç‚ºå¯ä»¥ **åšäº‹ã€çš„æ™ºèƒ½é«”**ï¼Œè€Œéåƒ…åƒ…ã€Œå›æ‡‰ã€çš„èŠå¤©æ©Ÿå™¨äººã€‚

---

####ã€€**â€œTool Calling in Practice + Resourcesâ€ æµç¨‹åœ–**ï¼š

```
User Prompt + Relevant Resources â”€â”€â–¶ LLM
                 â”‚
                 â–¼
        â”Œâ”€â”€ Decision: Use Tool? â”€â”€â”
        â”‚ Yes                      â”‚ No
        â–¼                          â–¼
  LLM outputs JSON             LLMç›´æ¥ç”Ÿæˆå›ç­”
  { "tool": name, "args": {...} }
        â”‚
        â–¼
   Code parses JSON
   if tool == X: execute X(args)
        â–¼
   Execute tool/API/DB
        â–¼
   Receive result
        â”‚
        â–¼
  Append result to prompt context
  { role: "tool", content: result }
        â”‚
        â–¼
Prompt LLM again (with resources + tool result)
        â–¼
   LLM generates final response
```

### ğŸ§  æµç¨‹èªªæ˜

1. **Prompt + Resources**

   * ä½¿ç”¨è€…è¼¸å…¥å•é¡Œï¼Œç³»çµ±å…ˆæŠ“å–**ç›¸é—œè³‡æ–™**ï¼ˆå¦‚èˆªç­ç¥¨åƒ¹ã€å…¬å¸è³‡è¨Šï¼‰ï¼Œå°‡å…¶æ‹¼å…¥ prompt ä¸­ä½œç‚º contextï¼Œæå‡ LLM çš„èƒŒæ™¯çŸ¥è­˜ã€‚

2. **LLM åˆ¤æ–· & å·¥å…·å‘¼å«**

   * LLM è‹¥åµæ¸¬éœ€è¦æŸ¥ç¥¨åƒ¹æˆ–è¨ˆç®—ï¼Œå°±ä»¥ JSON æ ¼å¼å›å‚³å·¥å…·å‘¼å«æŒ‡ä»¤ï¼Œå¦‚ `{"tool": "get_ticket_price", "args": {"city":"Paris"}}`ã€‚

3. **ç¨‹å¼æ¥æ”¶ & åŸ·è¡Œå·¥å…·**

   * ç¨‹å¼è§£æ JSONï¼ŒåŸ·è¡Œå°æ‡‰å·¥å…·ï¼ˆä¾‹å¦‚å‘¼å«è³‡æ–™åº«/APIï¼‰ã€‚

4. **å·¥å…·å–å¾—çµæœ**

   * å·¥å…·å¾è³‡æ–™åº«æˆ– API æ‹¿åˆ°ç­”æ¡ˆï¼ˆå¦‚ï¼šParis æ©Ÿç¥¨ 500 USDï¼‰ã€‚

5. **çµæœå›é¥‹ LLM**

   * å°‡çµæœä»¥ `role: "tool"` çš„è¨Šæ¯å½¢å¼è£œå› LLM prompt è£¡ï¼Œè®“æ¨¡å‹åŸºæ–¼çµæœå†å›ç­”ã€‚

6. **LLM æœ€çµ‚å›æ‡‰**

   * LLM é‡æ–°ç”Ÿæˆå›ç­”ï¼Œæ•´åˆæ’å…¥çš„ context èˆ‡å·¥å…·çµæœï¼Œæä¾›å®Œæ•´ç­”æ¡ˆã€‚

---

### ğŸ—ï¸ æ ¸å¿ƒæ¦‚å¿µæ•´åˆ

* **Resources**ï¼šé€éå¦‚ RAG æŠ€è¡“ï¼Œæ™ºèƒ½é¸å–æœ€ç›¸é—œè³‡æ–™ä¸¦å¡å…¥ promptï¼Œè®“æ¨¡å‹æ›´å°ˆæ¥­ ã€‚
* **Tool Calling**ï¼šLLM å¯è‡ªä¸»æ±ºå®šæ˜¯å¦å‘¼å«å·¥å…·ï¼Œä¸¦ä»¥çµæ§‹åŒ– JSON æ ¼å¼ç™¼å‡ºå‘¼å«ï¼Œå†ç”±å¾Œç«¯åŸ·è¡Œã€‚
* **JSON + if parsing**ï¼šå¾Œç«¯ç”¨ if åˆ¤æ–·å·¥å…·åç¨±ä¸¦åŸ·è¡Œï¼Œå±¬æ¥µç°¡æ¶æ§‹ï¼Œç„¡é­”æ³•ï¼Œå»åŠ›é‡å¼·å¤§ã€‚

---

### âœ… å„ªå‹¢ä¸€è¦½

| åŠŸèƒ½     | å¥½è™•                              |
| ------ | ------------------------------- |
| è³‡æ–™æ³¨å…¥   | å‡ç´šå°ˆæ¥­åº¦ã€é™ä½å¹»è¦ºç¾è±¡                    |
| å·¥å…·è‡ªä¸»å‘¼å« | æ¨¡å‹å¯é¸æ“‡æ˜¯å¦ä½¿ç”¨å·¥å…·ï¼Œæå‡è§£é¡Œå½ˆæ€§              |
| æ§‹å»ºæµç¨‹é€æ˜ | å…¨æµç¨‹ JSON èˆ‡ç¨‹å¼æ§åˆ¶ï¼Œæ”¯æ´ç›£æ§èˆ‡ guardrails |

---

#### Practice example (get reply from ChatGPT and Evaluate answers by gemini-2.0-flash):
1_foundations/3_lab3.ipynb
    - What is your greatest accomplishment?
    - What is your greatest failure?
    - What is a challenge that you encountered and needed to overcome?

    Evaluation:
    - What is your current role?
    - What is your current salary?
    - What is your current location?
    - Do you hold a patent?
    - Do you have a flight license?
    - Do you have a driver's license?

## Week 1 Day 5
### Agentic Frameworks - No Frameworks using Tools

1_foundations/test_tools.py
1_foundations/4_lab4.ipynb
1_foundations/app.py

```cmd
cd 1_foundations
uv run test_tools.py
uv run app.py

```

#### Tools for LLMs
é€™å…©å€‹å‡½æ•¸ `record_user_details` å’Œ `record_unknown_question`ï¼Œæ­é…å°æ‡‰çš„ JSON schemaï¼Œç›®çš„åœ¨æ–¼è®“ LLM èƒ½å¤ é€éå·¥å…·å‘¼å«ï¼Œ**ä¸»å‹•ç´€éŒ„ä½¿ç”¨è€…çš„é‡è¦äº’å‹•è³‡è¨Š**ï¼Œå³ä½¿é€™äº›ä¸æ˜¯è‡ªç„¶èªè¨€å°è©±ä¸­ç›´æ¥å›ç­”çš„éƒ¨åˆ†ã€‚

---

## ğŸ” åŠŸèƒ½èªªæ˜ï¼š

### 1. `record_user_details`

#### âœ… ç›®çš„ï¼š

ç•¶ LLM åˆ¤æ–·èˆ‡ä½¿ç”¨è€…äº’å‹•æ·±å…¥ã€æœ‰æ½›åœ¨åˆä½œæ©Ÿæœƒæ™‚ï¼Œæœƒå¼•å°ä½¿ç”¨è€…ç•™ä¸‹è¯çµ¡æ–¹å¼ï¼ˆå¦‚ emailï¼‰ï¼Œä¸¦é€éé€™å€‹å·¥å…· **ç´€éŒ„è¯çµ¡è³‡è¨Š**ã€‚

#### ğŸ“¦ JSON Schema ç¯„ä¾‹ï¼š

```json
{
  "name": "record_user_details",
  "description": "ç´€éŒ„ä½¿ç”¨è€…è¯çµ¡æ–¹å¼ï¼Œå¦‚ email",
  "parameters": {
    "type": "object",
    "properties": {
      "email": {
        "type": "string",
        "description": "ä½¿ç”¨è€…çš„é›»å­éƒµä»¶åœ°å€"
      }
    },
    "required": ["email"]
  }
}
```
---

### 2. `record_unknown_question`

#### âœ… ç›®çš„ï¼š

ç•¶ LLM **ç„¡æ³•å›ç­”ä½¿ç”¨è€…æå•æ™‚ï¼ˆå³ä½¿å•é¡Œå¾ˆç‘£ç¢æˆ–éå°ˆæ¥­ï¼‰**ï¼Œå¯ä¸»å‹•å°‡é€™å€‹å•é¡Œè¨˜éŒ„ä¸‹ä¾†ï¼Œæ–¹ä¾¿å¾ŒçºŒæ”¹é€²æ¨¡å‹æˆ–è®“çœŸäººè£œç­”ã€‚

#### ğŸ“¦ JSON Schema ç¯„ä¾‹ï¼š

```json
{
  "name": "record_unknown_question",
  "description": "ç´€éŒ„ç„¡æ³•å›ç­”çš„å•é¡Œ",
  "parameters": {
    "type": "object",
    "properties": {
      "question": {
        "type": "string",
        "description": "ä½¿ç”¨è€…çš„å•é¡Œ"
      }
    },
    "required": ["question"]
  }
}
```
---

## ğŸ§  ç¸½çµï¼ˆä½¿ç”¨å ´æ™¯æ¯”è¼ƒï¼‰ï¼š

| å‡½æ•¸åç¨±                      | ç”¨é€”                | LLM è‡ªä¸»ä½¿ç”¨æƒ…å¢ƒ                  |
| ------------------------- | ----------------- | --------------------------- |
| `record_user_details`     | å„²å­˜ä½¿ç”¨è€… email ç­‰è¯çµ¡æ–¹å¼ | ä½¿ç”¨è€…é¡¯ç¤ºåˆä½œèˆˆè¶£æˆ–æ·±å…¥äº’å‹•              |
| `record_unknown_question` | ç´€éŒ„ç„¡æ³•å›ç­”çš„å•é¡Œ         | ä½¿ç”¨è€…å•äº† LLM ç„¡è³‡æ–™å¯å›ç­”çš„å•é¡Œï¼ˆåŒ…å«å†·é–€è©±é¡Œï¼‰ |

---

### âœ… ä½¿ç”¨ OpenAI Function Calling / Tool Calling çš„æ­£ç¢ºæ–¹å¼ï¼š

```python
tools = [{"type": "function", "function": record_user_details_json},
        {"type": "function", "function": record_unknown_question_json}]

...
response = openai.chat.completions.create(
    model="gpt-4o-mini",
    messages=messages,
    tools=tools
)
```
### ğŸ” èªªæ˜ï¼š

* `model="gpt-4o-mini"`ï¼šæŒ‡å®šè¦ä½¿ç”¨çš„æ¨¡å‹ã€‚
* `messages=messages`ï¼šæ­·å²å°è©±å…§å®¹ï¼ˆåŒ…å« system/user/assistant role çš„è¨Šæ¯ï¼‰ã€‚
* `tools=tools`ï¼šå‘Šè¨´æ¨¡å‹æœ‰å“ªäº›å·¥å…·ï¼ˆå‡½æ•¸ï¼‰å®ƒå¯ä»¥ä½¿ç”¨ï¼Œè®“æ¨¡å‹åœ¨éœ€è¦çš„æ™‚å€™è‡ªå‹•å›å‚³å·¥å…·å‘¼å«ï¼ˆtool callï¼‰çš„ JSON æ ¼å¼ã€‚

---

### ğŸ”§ å¦‚æœä½ å¸Œæœ› LLM åœ¨å¿…è¦æ™‚ä¸»å‹•ä½¿ç”¨å·¥å…·ï¼Œä½ é‚„å¯ä»¥åŠ å…¥ `tool_choice="auto"`ï¼ˆå¯é¸ï¼‰ï¼š

```python
response = openai.chat.completions.create(
    model="gpt-4o-mini",
    messages=messages,
    tools=tools,
    tool_choice="auto"  # å¯é¸ï¼Œé è¨­å°±æ˜¯ auto
)
```

é€™æ¨£æœƒè®“ LLM è‡ªç”±æ±ºå®šæ˜¯å¦ä½¿ç”¨å…¶ä¸­ä¸€å€‹ toolã€‚

---

#### Deploy app.py to Hugging Face Spaces
```cmd
cd 1_foundations
uv run gradio deploy

```
### ğŸ“¦uv run gradio deploy Work Through
Creating new Spaces Repo in 'D:\development\agents-ai\1_foundations'. Collecting metadata, press Enter to accept default value.
Enter Spaces app title [1_foundations]: **Career_Conversions**
Enter Gradio app file [app.py]: 
Enter Spaces hardware (cpu-basic, cpu-upgrade, cpu-xl, zero-a10g, t4-small, t4-medium, l4x1, l4x4, l40sx1, l40sx4, l40sx8, a10g-small, a10g-large, a10g-largex2, a10g-largex4, a100-large, h100, h100x8) [cpu-basic]:
Any Spaces secrets (y/n) [n]: **y**
Enter secret name (leave blank to end): **OPENAI_API_KEY**
Enter secret value for OPENAI_API_KEY: **sk-proj-ypFvL65EvbsmO7CbVMD5R...**
Enter secret name (leave blank to end): **PUSHOVER_USER**
Enter secret value for PUSHOVER_USER: **uvuq9thwa...**
Enter secret name (leave blank to end): **PUSHOVER_TOKEN**
Enter secret value for PUSHOVER_TOKEN: **aeuhfdmy82...**
Enter secret name (leave blank to end): 
Create Github Action to automatically update Space on 'git push'? [n]: 
Space available at https://huggingface.co/spaces/christseng898/Career_Conversions

### Special Notes:
- **README.md** will be created in the folder 1_foundations after deploy.
